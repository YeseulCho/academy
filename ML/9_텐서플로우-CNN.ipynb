{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea001f4ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3*3*1 이미지 준비, 2*2*1 필터 준비\n",
    "image = np.array([[[[1], [2], [3]],\n",
    "                  [[4], [5], [6]],\n",
    "                  [[7], [8], [9]]]], dtype=np.float32)\n",
    "\n",
    "image.shape\n",
    "plt.imshow(image.reshape(3, 3), cmap=\"Greys\") # 숫자를 받아들여서 바로 이미지화 시켜줌 # BUT 이미지 2차원으로 넘겨줘야함\n",
    "\n",
    "\"\"\"\n",
    "아래 그래프의 정사각형 하나당 \n",
    "    1  2  3\n",
    "    4  5  6\n",
    "    7  8  9     의 값이 들어가있음 \n",
    "\n",
    "여기서 2*2 필터의 가중치값이 1이라면 '1*1 + 1*2 + 1*4 + 1*5 ' 로 계산\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2, 2, 1)\n",
      "축의 방향을 바꿈: [[[[12.]\n",
      "   [16.]]\n",
      "\n",
      "  [[24.]\n",
      "   [28.]]]]\n",
      "차원 변경: [[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## padding 없이 convolution layer 추출\n",
    "\n",
    "# filter 만들기\n",
    "filter = tf.constant([[[[1.]], [[1.]]],\n",
    "                     [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "\n",
    "\n",
    "# CNN \n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "# 원본이미지, filter, stride(가로세로 한칸씩 이동한다) 가운데 두값이 실제값 양옆은 항상1\n",
    "#  padding=\"VALID\" : padding 없이\n",
    "\n",
    "\n",
    "# 세션 만들어주기\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "\n",
    "\n",
    "# shape 확인\n",
    "print(\"shape:\", conv2d_img.shape) # 원본 이미지에 filter로 특징을 뽑아낸 이미지는 2*2 의 결과로 나타남\n",
    "\n",
    "\n",
    "# 특징 뽑아내기\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "print(\"축의 방향을 바꿈:\", conv2d_img)\n",
    "\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(\"차원 변경:\", one_img.reshape(2, 2))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(2,2), cmap=\"Greys\") # 차원 변경한 값의 형태로 그래프에 나타남\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 3, 3, 1)\n",
      "축의 방향을 바꿈: [[[[12.]\n",
      "   [16.]\n",
      "   [ 9.]]\n",
      "\n",
      "  [[24.]\n",
      "   [28.]\n",
      "   [15.]]\n",
      "\n",
      "  [[15.]\n",
      "   [17.]\n",
      "   [ 9.]]]]\n",
      "차원 변경: [[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAC7CAYAAADVEFpBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJRklEQVR4nO3df6hfdR3H8ecrdYvhamuzNub8EV0k+2W6TUWQLRnoECdkcPdH/kC5IEo/KEgLDIJg9UeRLQzLYUaoYZFLFmMyS6PU3cnUzTG9SeB0YF5zNlzJ6t0f31N+fe+7u3t3Pud8v9t9PeDLPed7Pve+P1/Ga+d7vud830cRgZm94z39noDZoHEozBKHwixxKMwSh8IscSjMklqhkPQBSZslvVD9nHuYcf+WtL16bKhT06xpqnOeQtJ3gdcjYq2kW4C5EfG1HuP2R8TJNeZp1pq6odgNLI+IvZIWAr+PiLN6jHMo7JhR95jiQxGxF6D6+cHDjHuvpFFJj0u6smZNs0adeKQBkh4GFvTY9I0p1DktIl6R9GFgi6RnI+IvPWqNACMAs2bNOm9oaGgKJQbXgQMH+j2FYmbPnt3vKRSzbdu21yLilPx8K2+f0u/cDTwUEQ9MNO6cc86JzZs3H/XcBsmOHTv6PYViVqxY0e8pFCNpW0Qsyc/Xffu0AbimWr4GeLBH4bmSZlbL84GLgOdq1jVrTN1QrAVWSnoBWFmtI2mJpJ9WYz4KjEp6GngEWBsRDoUNrCMeU0wkIsaBS3o8PwrcUC3/CfhEnTpmbfIZbbPEoTBLHAqzxKEwSxwKs8ShMEscCrPEoTBLHAqzxKEwSxwKs8ShMEscCrPEoTBLHAqzxKEwSxwKs6RIKCRdKmm3pLGqKVrePlPS/dX2JySdUaKuWRNqh0LSCcCPgMuAs4E1ks5Ow64H/h4RHwG+D3ynbl2zppTYUywDxiLixYh4G7gPWJ3GrAZ+Vi0/AFwiSQVqmxVXIhSLgJe61vdUz/UcExEHgX3AvPyHJI1UnQRHx8fHC0zNbOpKhKLX//i5w9pkxhARd0bEkohYMm/eIZkxa0WJUOwBFnetnwq8crgxkk4E3g+8XqC2WXElQrEVGJJ0pqQZwDCdzoHdujsJXgVsCd+r2AZUrWZo0DlGkHQzsAk4AVgfETslfQsYjYgNwF3AzyWN0dlDDNeta9aU2qEAiIiNwMb03G1dy/8EPleillnTfEbbLHEozBKHwixxKMwSh8IscSjMEofCLHEozBKHwixxKMwSh8IscSjMEofCLHEozBKHwixxKMyStpqhXSvpb5K2V48bStQ1a0Ltb951NUNbSadBwVZJGyLiuTT0/oi4uW49s6a11QzN7JhR4jvavZqhnd9j3GclXQw8D3w5Il7KAySNACMAM2fOZHj4+OhvsGXLln5PoZgnn3yy31NoXFvN0H4LnBERnwQe5p0Wmu/+pa5maDNmzCgwNbOpa6UZWkSMR8S/qtWfAOcVqGvWiFaaoUla2LV6BbCrQF2zRrTVDO0Lkq4ADtJphnZt3bpmTWmrGdqtwK0lapk1zWe0zRKHwixxKMwSh8IscSjMEofCLHEozBKHwixxKMwSh8IscSjMEofCLHEozBKHwixxKMwSh8IsKdUMbb2kVyXtOMx2Sbq9apb2jKRzS9Q1a0KpPcXdwKUTbL8MGKoeI8AdheqaFVckFBHxKJ3vXh/OauCe6HgcmJOaGZgNjLaOKXo1TFvUUm2zKSnSuGASJtMw7ZAOgWb90Nae4ogN08AdAm0wtBWKDcDV1adQFwD7ImJvS7XNpqTI2ydJ9wLLgfmS9gDfBE4CiIgf0+kJtQoYA94CritR16wJpZqhrTnC9gBuKlHLrGk+o22WOBRmiUNhljgUZolDYZY4FGaJQ2GWOBRmiUNhljgUZolDYZY4FGaJQ2GWOBRmiUNhljgUZolDYZa01SFwuaR9krZXj9tK1DVrQqkWN3cD64B7JhjzWERcXqieWWPa6hBodsxoqxkawIWSnqbT7+mrEbEzD+huhrZgwQLWrl3b4vSa8/LLL/d7CsUsXbq031NoXFsH2k8Bp0fEp4AfAr/pNai7GdqcOXNamprZu7USioh4MyL2V8sbgZMkzW+jttlUtRIKSQskqVpeVtUdb6O22VS11SHwKuBGSQeBA8Bw1SDNbOC01SFwHZ2PbM0Gns9omyUOhVniUJglDoVZ4lCYJQ6FWeJQmCUOhVniUJglDoVZ4lCYJQ6FWeJQmCUOhVniUJglDoVZUjsUkhZLekTSLkk7JX2xxxhJul3SmKRnJJ1bt65ZU0p88+4g8JWIeErSbGCbpM0R8VzXmMuAoepxPnBH9dNs4NTeU0TE3oh4qlr+B7ALWJSGrQbuiY7HgTmSFtatbdaEoscUks4APg08kTYtAl7qWt/DocFB0oikUUmjb7zxRsmpmU1asVBIOhn4FfCliHgzb+7xK4d083AzNBsEpbqOn0QnEL+IiF/3GLIHWNy1fiqd9plmA6fEp08C7gJ2RcT3DjNsA3B19SnUBcC+iNhbt7ZZE0p8+nQR8HngWUnbq+e+DpwG/2+GthFYBYwBbwHXFahr1ojaoYiIP9L7mKF7TAA31a1l1gaf0TZLHAqzxKEwSxwKs8ShMEscCrPEoTBLHAqzxKEwSxwKs8ShMEscCrPEoTBLHAqzxKEwSxwKs6StZmjLJe2TtL163Fa3rllT2mqGBvBYRFxeoJ5Zo9pqhmZ2zGirGRrAhZKelvQ7SR8rWdesJHV6ChT4Q51maH8Avp17P0l6H/CfiNgvaRXwg4gY6vE3RoCRavUsYHeRyU1sPvBaC3XacLy8lrZex+kRcUp+skgoqmZoDwGbJuj91D3+r8CSiOj7P6Ck0YhY0u95lHC8vJZ+v45WmqFJWlCNQ9Kyqu543dpmTWirGdpVwI2SDgIHgOEo9b7NrLC2mqGtA9bVrdWQO/s9gYKOl9fS19dR7EDb7HjhyzzMkmkbCkmXStpd3Yfvln7P52hJWi/pVUk7+j2XuiZzyVAr85iOb58knQA8D6ykc++MrcCaHpemDDxJFwP76dw+7eP9nk8d1S3fFnZfMgRc2fa/y3TdUywDxiLixYh4G7iPzn35jjkR8Sjwer/nUcKgXDI0XUMxqXvwWf8c4ZKhRk3XUEzqHnzWH0e4f2LjpmsofA++ATWJ+yc2brqGYiswJOlMSTOAYTr35bM+muT9Exs3LUMREQeBm4FNdA7mfhkRO/s7q6Mj6V7gz8BZkvZIur7fc6rhf5cMfabrW5qr2p7EtPxI1mwi03JPYTYRh8IscSjMEofCLHEozBKHwixxKMwSh8Is+S/Q/gpCNlzS8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## padding을 이용한 convolution layer 추출\n",
    "\n",
    "# filter 만들기\n",
    "filter = tf.constant([[[[1.]], [[1.]]],\n",
    "                     [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "\n",
    "\n",
    "# CNN \n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "# padding=\"SAME\" : 원본과 똑같은 크기로 패딩을 추가해주겠다\n",
    "\"\"\"\n",
    "    0  0  0  0  0\n",
    "    0  1  2  3  0\n",
    "    0  4  5  6  0\n",
    "    0  7  8  9  0   으로 padding 채운 후 \n",
    "    0  0  0  0  0\n",
    "\n",
    "filter(2*2)는 padding으로 채운 부분까지 계산하여 convolution layer 추출한다\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 세션 만들어주기\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "\n",
    "\n",
    "# shape 확인\n",
    "print(\"shape:\", conv2d_img.shape) # 원본 이미지에 filter로 특징을 뽑아낸 이미지는 2*2 의 결과로 나타남\n",
    "\n",
    "\n",
    "# 특징 뽑아내기\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "print(\"축의 방향을 바꿈:\", conv2d_img)\n",
    "\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(\"차원 변경:\", one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(3,3), cmap=\"Greys\") # 차원 변경한 값의 형태로 그래프에 나타남\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 3, 3, 3)\n",
      "축의 방향을 바꿈: [[[[ 12.]\n",
      "   [ 16.]\n",
      "   [  9.]]\n",
      "\n",
      "  [[ 24.]\n",
      "   [ 28.]\n",
      "   [ 15.]]\n",
      "\n",
      "  [[ 15.]\n",
      "   [ 17.]\n",
      "   [  9.]]]\n",
      "\n",
      "\n",
      " [[[120.]\n",
      "   [160.]\n",
      "   [ 90.]]\n",
      "\n",
      "  [[240.]\n",
      "   [280.]\n",
      "   [150.]]\n",
      "\n",
      "  [[150.]\n",
      "   [170.]\n",
      "   [ 90.]]]\n",
      "\n",
      "\n",
      " [[[-12.]\n",
      "   [-16.]\n",
      "   [ -9.]]\n",
      "\n",
      "  [[-24.]\n",
      "   [-28.]\n",
      "   [-15.]]\n",
      "\n",
      "  [[-15.]\n",
      "   [-17.]\n",
      "   [ -9.]]]]\n",
      "차원 변경: [[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "차원 변경: [[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "차원 변경: [[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3개의 필터 사용(2*2*1*3)\n",
    "\n",
    "# filter 만들기\n",
    "filter = tf.constant([[[[1., 10, -1]], [[1., 10, -1]]],\n",
    "                     [[[1., 10, -1]], [[1., 10, -1]]]])\n",
    "filter.shape\n",
    "\n",
    "\n",
    "# CNN \n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "# padding=\"SAME\" : 원본과 똑같은 크기로 패딩을 추가해주겠다\n",
    "\"\"\"\n",
    "    0  0  0  0  0\n",
    "    0  1  2  3  0\n",
    "    0  4  5  6  0\n",
    "    0  7  8  9  0   으로 padding 채운 후  \n",
    "    0  0  0  0  0\n",
    "\n",
    "filter(2*2)는 padding으로 채운 부분까지 계산하여 convolution layer 추출한다\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 세션 만들어주기\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "\n",
    "\n",
    "# shape 확인\n",
    "print(\"shape:\", conv2d_img.shape) # 원본 이미지에 filter로 특징을 뽑아낸 이미지는 2*2 의 결과로 나타남\n",
    "\n",
    "\n",
    "# 특징 뽑아내기\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "print(\"축의 방향을 바꿈:\", conv2d_img)\n",
    "\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(\"차원 변경:\", one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(one_img.reshape(3,3), cmap=\"Greys\") # 차원 변경한 값의 형태로 그래프에 나타남\n",
    "    \n",
    "sess.close()\n",
    "\n",
    "# 각각의 영역을 filter를 이용해서 추출해내기\n",
    "#  따로따로 읽어들여서 나중에 한장의 이미지로 나타냄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4]]]]\n"
     ]
    }
   ],
   "source": [
    "## MaxPooling(2*2)\n",
    "\n",
    "# filter 만들기\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]],\n",
    "                      [[2], [1]]]])\n",
    "\n",
    "# 최대값이 어떻게 추출되는지 알아보기\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"VALID\") # 2*2짜리의 커널 크기 지정\n",
    "\n",
    "# 세션\n",
    "sess = tf.Session()\n",
    "\n",
    "# 결과값\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p) # 1*1 이미지로 추출됨 # 가중치 값이 따로 필요없음 # 필터를 덮어놓은 위치에서 가장 큰값을 골라내면 됨 \n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST를 이용한 CNN\n",
    "Lab11-CNN.pdf 슬라이드 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-56b35f4548e8>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x270a4a74208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "img = mnist.train.images[0] # 첫번째 이미지 뽑아오기\n",
    "img.shape # 한장불러오면 일차원배열\n",
    "\n",
    "plt.imshow(img.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값 준비\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 Convolution Layer 준비\n",
    "# 필터 : 크기 3*3, 개수 32, 색상수 1\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    # [-1, 28, 28, 1] : 사용할 개수, -1이면 개수 상관 없다는 뜻 / 가로 / 세로 / 색상수-> 4차원으로 맞춰줘야함\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "    # [3, 3, 1, 32] : 가로 / 세로 / 색상수 / 개수 # stddev=0.01 : 랜덤값의 범위 표준편차 범위 안에서 뽑아짐    \n",
    "\n",
    "# 한번만 실행하도록 shell 따로 만들어서 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer1(가중치 연산해서 뽑아냄)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L1) # convolutional layer 로 뽑았을때결과에 대한 크기 \n",
    "\n",
    "# MAX Pooling 넣기전에 relu 에 통과시켜보기\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1) # 분류값 알아내기\n",
    "\n",
    "# Pooling layer1(큰 값 뽑아내기 때문에 따로 가중치값 뽑아낼 필요 없음)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "    # 입력할 이미지 / 필터 크기(가운데 있는 두개의 값이 실제값) / strides 몇칸씩 움직일것인지, 2칸씩 움직이게되면 좀 줄어들것 / padding 할거다\n",
    "print(L1) # 14*14 이미지가 주어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 Convolution Layer 준비 - 특징 또 뽑기 / 중요한 특징을 더 뽑아내기\n",
    "# 필터 : 크기 3*3, 개수 64, 색상수 1\n",
    "\n",
    "# 데이터는 이미 있으니\n",
    "# 필터만 준비\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "    # 1장의 이미지를 32조각(위에 maxpool결과값)으로 가져왔으니 32장으로 보기 이걸 다시 64개로 쪼개겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional layer2\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L2)\n",
    "\n",
    "# MAX Pooling 넣기전에 relu 에 통과시켜보기\n",
    "L2 = tf.nn.relu(L2)\n",
    "print(L2) \n",
    "\n",
    "# Pooling layer1\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L2) # 7*7 이미지로가 절반으로 줄어든것을 볼수있다 # 한장의 이미지를 64개로 쪼개놓은것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-562308e20156>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch : 0001 cost : 0.738878985\n",
      "Epoch : 0002 cost : 0.153591779\n",
      "Epoch : 0003 cost : 0.106411161\n",
      "Epoch : 0004 cost : 0.083966346\n",
      "Epoch : 0005 cost : 0.070054032\n",
      "Epoch : 0006 cost : 0.062735030\n",
      "Epoch : 0007 cost : 0.054976204\n",
      "Epoch : 0008 cost : 0.049074804\n",
      "Epoch : 0009 cost : 0.044645795\n",
      "Epoch : 0010 cost : 0.042102311\n",
      "Epoch : 0011 cost : 0.037113254\n",
      "Epoch : 0012 cost : 0.034654723\n",
      "Epoch : 0013 cost : 0.032430345\n",
      "Epoch : 0014 cost : 0.030715532\n",
      "Epoch : 0015 cost : 0.027444974\n",
      "훈련 종료\n"
     ]
    }
   ],
   "source": [
    "# Fully connected layer 작성(Dense Layer)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 500\n",
    "\n",
    "# tensor graph 작성\n",
    "#---------------------\n",
    "\n",
    "# 입력 데이터 준비\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64]) # 2차원으로 바꿔주기\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 10]))  # 크기 / 출력개수 10개 \n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 비율 계산\n",
    "logit = tf.matmul(L2, W3) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# tensor graph 실행\n",
    "#-----------------------\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for epoch in range(training_epochs):\n",
    "    fetal_batch = int(mnist.train.num_examples/batch_size)\n",
    "    avg_cost = 0\n",
    "        \n",
    "    for i in range(fetal_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/fetal_batch\n",
    "            \n",
    "    print(\"Epoch :\", \"%04d\"%(epoch+1), \"cost :\", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "print(\"훈련 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.9833\n"
     ]
    }
   ],
   "source": [
    "# 정확도 알아보기 \n",
    "\n",
    "correct_predict = tf.equal(tf.argmax(logit, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))\n",
    "sess.close()\n",
    "\n",
    "# 기본 성능 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교통 표지판 인식\n",
    "\n",
    "http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset\n",
    "\n",
    "downloads - this link - GTSRB_Final_Test_GT.zip, GTSRB_Final_Test_Images.zip, GTSRB_Final_Training_Images.zip 3개 다운받기\n",
    "\n",
    "\n",
    "이미지(32 * 32) -> Convolution Layer1 -> Max Pooling -> Convolution Layer2 -> Max Pooling -> FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리를 위한 패키지\n",
    "import glob # 파일 여러개 동시에 불러올 때\n",
    "from skimage.color import rgb2lab # rgb색상을 흑백으로 바꿔줌\n",
    "from skimage.transform import resize \n",
    "from collections import namedtuple\n",
    "\n",
    "# 랜덤값 고정\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 상수 정의\n",
    "N_CLASSES = 43               # 최종 출력개수\n",
    "RESIZED_IMAGE = (32, 32)     # 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = namedtuple(\"Dataset\", [\"X\", \"y\"]) # namedtuple : 수정불가 / 변수 안전하게 보관 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs]).astype(np.float32) # 차원 늘려주기\n",
    "        \n",
    "## ppm형식 파일 불러오는 함수 : 쓰기좋은 형태로 전처리 다한 상태로 파일 불러오도록 함수 작성하기 \n",
    "def read_dataset_ppm(rootpath, n_labels, resize_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # 사진 파일 불러오기\n",
    "    for c in range(n_labels): # Final_Training - Images 폴더 개수 43개 이므로 n_labels = 43\n",
    "        full_path = rootpath + \"/\" + format(c, \"05d\") + \"/\"\n",
    "            # 폴더명을 어떻게 지정해주냐에 따라 파일불러오는 방식의 여부가 달라짐 # 이거는 5자리 숫자여서 불러오기 편하다~~\n",
    "        \n",
    "        # 이미지 숫자로 바꿔주기 \n",
    "        for img_name in glob.glob(full_path + \"*.ppm\") :\n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "                # imshow( 숫자를 이미지로 ) imread(이미지를 숫자로 바꿔주는애)\n",
    "            \n",
    "            # img rgb색상에서 lab 색상으로 변환 \n",
    "            img = rgb2lab(img/255.0)[:, :, 0]\n",
    "                # rgb는 255개씩이므로 255로 나눠줌 # [:, :, 0] 3차원으로만들어주기\n",
    "            \n",
    "            # 크기 맞춰주기\n",
    "            if resize_to:\n",
    "                img = resize(img, resize_to)\n",
    "                    # resize ; 이미지 사이즈 한번에 줄여주기\n",
    "                    \n",
    "            # labeling(one-hot) : 교통표지판의 답을 뭐라고 할 것인가\n",
    "            # one hot encoding 한곳에만 값 주어주기 ex) 세번째 사진이면 0 0 1 0 0 0 0 0 0 0 .....\n",
    "            label = np.zeros((n_labels), dtype=np.float32)\n",
    "            label[c] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "            \n",
    "    return Dataset(X=to_tf_format(images), y=np.matrix(labels).astype(np.float32))\n",
    "            # 위에 namedtuple로 만들어놓은거 # 미리 2차원으로 담아서 넣어두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 보기\n",
    "dataset = read_dataset_ppm(\"data/traffic/GTSRB/Final_Training/Images\", N_CLASSES, RESIZED_IMAGE)\n",
    "    # 상위폴더(Images) 까지 지정해주면 그 안에있는 모든 폴더와 파일 가져옴\n",
    "# print(dataset.X.shape) # (39209, 32, 32, 1)  # 32*32에 색상 1 \n",
    "# print(dataset.y.shape) # (39209, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f5573d4ac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 확인하기\n",
    "\n",
    "# one hot 레이블 확인\n",
    "## 첫번째 폴더의 첫번째 이미지\n",
    "print(dataset.y[0, :]) # 첫번째 데이터이니까 첫번째에만 1써져있고 나머지는 다 0~~~~~~~~~\n",
    "plt.imshow(dataset.X[0, :, :, :].reshape(RESIZED_IMAGE))\n",
    "\n",
    "## 마지막 폴더의 마지막 이미지\n",
    "print(dataset.y[-1, :])\n",
    "plt.imshow(dataset.X[-1, :, :, :].reshape(RESIZED_IMAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29406, 32, 32, 1)\n",
      "(9803, 32, 32, 1)\n",
      "(29406, 43)\n",
      "(9803, 43)\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터와 테스트용 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(dataset.X.shape[0]), test_size=0.25, random_state=101) \n",
    "                       # 데이터 차원이 다르므로 따로 받아옴\n",
    "                                       \n",
    "X_train = dataset.X[idx_train, :, :, :]\n",
    "X_test = dataset.X[idx_test, :, :, :]\n",
    "y_train = dataset.y[idx_train, :]\n",
    "y_test = dataset.y[idx_test, :]\n",
    "                                       \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0] # (test주도 개발방식에 맞는 코드)assert : 디버깅 모드 / 릴리즈 모드일때는 작동을 안함\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples) # 29406개 sample을 섞어서 순서를 세워둠\n",
    "    else :\n",
    "        idx = list(range(n_samples))\n",
    "        \n",
    "    for k in range(int(np.ceil(n_samples/batch_size))):\n",
    "        from_idx = k * batch_size\n",
    "        to_idx = (k+1) * batch_size\n",
    "        yield X[idx[from_idx:to_idx], :, :, :], y[idx[from_idx:to_idx], :]        \n",
    "        # yield 일종의 스레드 기법; 안정적으로 작업이 진행되게 하게끔 하기위한 하나의 방법 \n",
    "        # (현재 데이터를 하나씩 끌어오고 있음. 이것을 좀더 안정적으로 처리 ?>?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "for mb in minibatcher(X_train, y_train, 10000, True):# 10000개씩 끊어서 실행\n",
    "    print(mb[0].shape, mb[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_no_activation_layer(in_tensors, n_units) :\n",
    "    W = tf.get_variable(\"fc_W\", [in_tensors.get_shape()[1], n_units], \n",
    "                        tf.float32, tf.contrib.layers.xavier_initializer()) # xavier 쓸거라서 get_variable사용함 \n",
    "    b = tf.get_variable(\"fc_b\", [n_units], tf.float32, tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.matmul(in_tensors, W) + b\n",
    "\n",
    "def fc_layer(in_tensors, n_units) :\n",
    "    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units)) # leaky_relu : 최소값을 음수까지 쓸수있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "\n",
    "       convolution layer -> relu -> max pooling -> drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size, kernel_size, in_tensors.get_shape()[3], n_units],\n",
    "                        tf.float32, tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"conv_b\", [n_units], tf.float32, tf.constant_initializer(0.0))\n",
    "    return tf.nn.leaky_relu(tf.nn.conv2d(in_tensors, W, [1, 1, 1, 1], \"SAME\")) # [1, 1, 1, 1] : stride 한칸씩 이동, padding=\"SAME\"\n",
    "\n",
    "def maxpool_layer(in_tensors, sampling): # sampling : 필터사이즈\n",
    "    return tf.nn.max_pool(in_tensors, ksize=[1, sampling, sampling, 1], strides=[1, sampling, sampling, 1], padding=\"SAME\")\n",
    "#                                      필터사이즈랑 스트라이드 사이즈 똑같이 하겠다\n",
    "\n",
    "def dropout(in_tensors, keep_proba, is_training):\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors, keep_proba), lambda:in_tensors) \n",
    " # true면 훈련중, false면 test중 / lambda 쓰는 이유가 뭐라구용.....? 조건주는거..?\n",
    " # lambda:tf.nn.dropout(in_tensors, keep_proba) : True면 dropout 하고 몇 %만 남기고 나머지는 끊어 버려라\n",
    " # lambda:in_tensors : False면 dropout 안하고 그냥in_tensors값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summary\n",
    "\n",
    "    - convolution 1st : 5*5, 32 필터\n",
    "    - convolution 2nd : 5*5, 64 필터\n",
    "    - FC(fully connected) : 1024 unit(출력개수 1024개로 연결)\n",
    "    - Dropout : 총 40% (40% 버리고 60% 훈련)(첫번째 20%, 두번째 20% 총 40%)\n",
    "    - Activation Function : Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성\n",
    "def model(in_tensors, is_training):\n",
    "    \n",
    "    # 1st conv layer : 5*5, 32 filter, 2x maxpool, 20% drop out\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n",
    "         # 입력데이터, 필터크기, 출력개수(layer unit의 개수, filter 개수) # 출력값이 maxpool에게는 입력값이므로 전체 넣어주기, maxpool 개수 2\n",
    "        l1_out = dropout(l1, 0.8, is_training) \n",
    "         # 입력값, 남기는거(20% 버릴거니까 남기는건 80%), 출력값인가?ㅋㅋㅋㅋ\n",
    "    \n",
    "    \n",
    "    # 2nd conv layer : 5*5, 64 filter, 2x maxpool, 20% drop out\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(l1_out, 5, 64), 2)\n",
    "        l2_out = dropout(l2, 0.8, is_training)   \n",
    "    \n",
    "    \n",
    "    # 평면화(1차원으로 평면화)\n",
    "    # 전처리 끝나고 나서 FC로 넘길때 차원(4차원 안되니까 2차원으로) 풀어서 넘겨줌 \n",
    "    # FC에게 값을 부드럽게 넘겨주기 위해서 값을 1차원으로 풀어서 넘겨줌\n",
    "    # 그럼 FC 에서 개수 정할때 자연스럽게 차원하나 높여주게 됨 그래서 2차원되니까 걍 1차원으로 풀어주라고오오오오오오오옹놀오란올\n",
    "    with tf.variable_scope(\"flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out) # flatten : 다차원으로 1차원으로 펼쳐주는 함수 \n",
    "    \n",
    "    \n",
    "    # FC : 1024 neurons, 40% dropout\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, 1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "    \n",
    "    \n",
    "    # output\n",
    "    with tf.variable_scope(\"out\"):\n",
    "        out_tensors = fc_no_activation_layer(l3_out, N_CLASSES) # 최종출력개수 실제 출력의 개수(N_CLASSES) 지정해줘야함 \n",
    "        \n",
    "    return out_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 사용할(최종적으로) 함수 : 얘만 호출하면 그동안 만들었던 모든 함수 실행되도록 하자 \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, learning_rate, max_epochs, batch_size):\n",
    "    \n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None, RESIZED_IMAGE[0], RESIZED_IMAGE[1], 1)) \n",
    "                                                                # 크기도 되도록이면 변수로 지정하자 / shape 색상수 1\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape = (None, N_CLASSES)) # N_CLASSES : 최종 가중치에 대한 결과값\n",
    "    is_training = tf.placeholder(tf.bool) # TRUE FALSE 중 하나만 들어가면 되니 bool 사용\n",
    "    \n",
    "    logit = model(in_X_tensors_batch, is_training) # model함수에서 만들은 최종결과 받아올수있음\n",
    "    out_y_pred = tf.nn.softmax(logit) # 결과에 대한 예측값\n",
    "    loss_score = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels = in_y_tensors_batch)\n",
    "    loss = tf.reduce_mean(loss_score) # 비용\n",
    "    train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epochs in range(max_epochs):\n",
    "        print(\"Epoch : \", epochs)\n",
    "        tf_score = []\n",
    "        \n",
    "        for mb in minibatcher(X_train, y_train, batch_size, True):\n",
    "            tf_output = sess.run([train, loss], feed_dict = {in_X_tensors_batch:mb[0], \n",
    "                                                 in_y_tensors_batch:mb[1],\n",
    "                                                 is_training:True}) # tf_output : 변수 하나로 쓰면 list로 값 전달되요...\n",
    "            tf_score.append(tf_output[1])\n",
    "            \n",
    "        print(\"     training_loss_score = \", np.mean(tf_score))        \n",
    "        \n",
    "    \n",
    "    # Test\n",
    "    print(\"TEST SET PERFORMANCE\")\n",
    "    y_test_pred, test_loss = sess.run([out_y_pred, loss], feed_dict = {in_X_tensors_batch:X_test, \n",
    "                                                 in_y_tensors_batch:y_test,\n",
    "                                                 is_training:False})\n",
    "    \n",
    "    print(\"test_loss_score\", test_loss)\n",
    "    y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n",
    "    y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n",
    "    print(classification_report(y_test_true_classified, y_test_pred_classified))\n",
    "    \n",
    "    ## \n",
    "    cm = confusion_matrix(y_test_true_classified, y_test_pred_classified)\n",
    "\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.imshow(np.log2(cm+1), interpolation=\"nearest\", cmap=plt.get_cmap(\"tab20\"))\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-11-ae615a8946bb>:12: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-12-337166932bf7>:23: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Epoch :  0\n",
      "     training_loss_score =  4.52819\n",
      "Epoch :  1\n",
      "     training_loss_score =  0.7159366\n",
      "Epoch :  2\n",
      "     training_loss_score =  0.36047843\n",
      "Epoch :  3\n",
      "     training_loss_score =  0.22782047\n",
      "Epoch :  4\n",
      "     training_loss_score =  0.16415915\n",
      "Epoch :  5\n",
      "     training_loss_score =  0.12713024\n",
      "Epoch :  6\n",
      "     training_loss_score =  0.108850084\n",
      "Epoch :  7\n",
      "     training_loss_score =  0.08729171\n",
      "Epoch :  8\n",
      "     training_loss_score =  0.07975148\n",
      "Epoch :  9\n",
      "     training_loss_score =  0.071247295\n",
      "TEST SET PERFORMANCE\n",
      "test_loss_score 0.056822386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        67\n",
      "           1       0.98      0.99      0.98       539\n",
      "           2       0.97      0.99      0.98       558\n",
      "           3       0.98      0.98      0.98       364\n",
      "           4       1.00      0.99      0.99       487\n",
      "           5       0.99      0.95      0.97       479\n",
      "           6       1.00      1.00      1.00       105\n",
      "           7       0.99      0.98      0.98       364\n",
      "           8       0.99      1.00      0.99       340\n",
      "           9       1.00      1.00      1.00       384\n",
      "          10       0.99      0.99      0.99       513\n",
      "          11       1.00      0.97      0.99       334\n",
      "          12       0.99      0.99      0.99       545\n",
      "          13       0.99      0.99      0.99       537\n",
      "          14       0.99      1.00      0.99       213\n",
      "          15       0.99      0.99      0.99       164\n",
      "          16       1.00      1.00      1.00        98\n",
      "          17       1.00      1.00      1.00       281\n",
      "          18       0.98      1.00      0.99       286\n",
      "          19       0.98      1.00      0.99        56\n",
      "          20       0.99      0.95      0.97        78\n",
      "          21       0.99      0.98      0.98        95\n",
      "          22       0.99      1.00      0.99        97\n",
      "          23       0.99      0.99      0.99       123\n",
      "          24       1.00      1.00      1.00        77\n",
      "          25       0.98      0.99      0.99       401\n",
      "          26       0.97      0.99      0.98       135\n",
      "          27       0.97      1.00      0.98        60\n",
      "          28       0.99      0.99      0.99       123\n",
      "          29       0.97      1.00      0.99        69\n",
      "          30       0.98      0.97      0.98       115\n",
      "          31       0.99      0.98      0.99       178\n",
      "          32       0.98      1.00      0.99        55\n",
      "          33       0.98      0.99      0.99       177\n",
      "          34       1.00      0.99      1.00       103\n",
      "          35       1.00      1.00      1.00       277\n",
      "          36       1.00      0.99      0.99        78\n",
      "          37       0.98      0.98      0.98        63\n",
      "          38       1.00      1.00      1.00       540\n",
      "          39       1.00      1.00      1.00        60\n",
      "          40       0.98      1.00      0.99        85\n",
      "          41       1.00      1.00      1.00        47\n",
      "          42       1.00      1.00      1.00        53\n",
      "\n",
      "    accuracy                           0.99      9803\n",
      "   macro avg       0.99      0.99      0.99      9803\n",
      "weighted avg       0.99      0.99      0.99      9803\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "train_model(X_train, y_train, X_test, y_test, 0.001, 10, 256) \n",
    "    # learning_rate = 0.001 / epoch 데이터의 반복횟수 10 / 256개로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
