{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://hunkim.github.io/ml/   -   Linear Regression의 개념 비디오 강의슬라이드, 실습슬라이드 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.666664\n",
      "70.98\n",
      "67.386665\n",
      "63.88667\n",
      "60.479992\n",
      "57.166668\n",
      "53.946674\n",
      "50.819996\n",
      "47.78667\n",
      "44.84666\n",
      "42.0\n",
      "39.246666\n",
      "36.586662\n",
      "34.020004\n",
      "31.546667\n",
      "29.166666\n",
      "26.88\n",
      "24.686666\n",
      "22.58667\n",
      "20.58\n",
      "18.666666\n",
      "16.846666\n",
      "15.12\n",
      "13.486667\n",
      "11.946668\n",
      "10.5\n",
      "9.146666\n",
      "7.886667\n",
      "6.72\n",
      "5.646666\n",
      "4.6666665\n",
      "3.78\n",
      "2.986667\n",
      "2.2866664\n",
      "1.68\n",
      "1.1666666\n",
      "0.7466666\n",
      "0.42000008\n",
      "0.18666662\n",
      "0.04666671\n",
      "0.0\n",
      "0.04666671\n",
      "0.18666674\n",
      "0.41999987\n",
      "0.7466665\n",
      "1.1666666\n",
      "1.6800003\n",
      "2.2866673\n",
      "2.986666\n",
      "3.7799995\n",
      "4.6666665\n",
      "5.646666\n",
      "6.720001\n",
      "7.8866653\n",
      "9.146668\n",
      "10.5\n",
      "11.946666\n",
      "13.486669\n",
      "15.119998\n",
      "16.84667\n",
      "18.666666\n",
      "20.579996\n",
      "22.58667\n",
      "24.686666\n",
      "26.880005\n",
      "29.166666\n",
      "31.546661\n",
      "34.020004\n",
      "36.586662\n",
      "39.24667\n",
      "42.0\n",
      "44.84666\n",
      "47.786663\n",
      "50.820007\n",
      "53.946674\n",
      "57.166668\n",
      "60.479992\n",
      "63.886658\n",
      "67.386665\n",
      "70.98\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1, 2, 3] # 입력값\n",
    "y_train = [1, 2, 3] # 결과값\n",
    "\n",
    "# wx + b = y  \n",
    "# x_train, y_train 값에 위의 식이 적합하려면\n",
    "# w = 1, b = 0의 값이 나와야한다\n",
    "# tensorflow는 이 값을 찾아줌\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "# 가설 준비(Wx + b)\n",
    "hypot = W * x_train # 가중치 기준으로 준비하기, b는 일단 제외시켜보자\n",
    "\n",
    "# 비용함수 준비 # 실습슬라이드 p.7 중간식 참고\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))   \n",
    "# tf.square : 제곱 / tf.reduce_mean : 전체데이터 평균 구해줌\n",
    "# --------------------- 텐서플로우의 그래프 완성 --------------------- # \n",
    "\n",
    "\n",
    "# 비용함수를 그래프로 그리기\n",
    "sess = tf.Session()\n",
    "\n",
    "cost_val=[]\n",
    "\n",
    "for i in range(-30, 50) :\n",
    "    cost_result = sess.run(cost, feed_dict={W:i*0.1}) \n",
    "    # cost : 최종값만 입력하면 앞에 다 처리됨\n",
    "    # feed_dict={W:i*0.1} : hypot에 입력값은 준비가 되었는데 W값은 뭔지 모름 / W에 i*0.1 씩 학습시키겠다\n",
    "    \n",
    "    print(cost_result) \n",
    "    # cost_result : W가 찾고자하는 비용 최저점 찾기  \n",
    "    \n",
    "    cost_val.append(cost_result)\n",
    "    \n",
    "# 그래프 \n",
    "plt.plot(cost_val)\n",
    "# 경사하강(Gradient Descent)\n",
    "# learning rate\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강 알고리즘을 이용한 가중치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 31.310312271118164, W : [-0.0237335]\n",
      "step : 1, cost : 13.515498161315918, W : [0.4540088]\n",
      "step : 2, cost : 7.087120056152344, W : [0.7088047]\n",
      "step : 3, cost : 4.529674053192139, W : [0.84469587]\n",
      "step : 4, cost : 3.4134607315063477, W : [0.9171711]\n",
      "step : 5, cost : 2.888620376586914, W : [0.9558246]\n",
      "step : 6, cost : 2.628751277923584, W : [0.9764398]\n",
      "step : 7, cost : 2.495856523513794, W : [0.98743457]\n",
      "step : 8, cost : 2.426600694656372, W : [0.9932984]\n",
      "step : 9, cost : 2.3901262283325195, W : [0.9964258]\n",
      "step : 10, cost : 2.3708040714263916, W : [0.9980938]\n",
      "step : 11, cost : 2.3605360984802246, W : [0.9989834]\n",
      "step : 12, cost : 2.3550703525543213, W : [0.9994578]\n",
      "step : 13, cost : 2.352158784866333, W : [0.9997108]\n",
      "step : 14, cost : 2.3506064414978027, W : [0.99984574]\n",
      "step : 15, cost : 2.3497791290283203, W : [0.99991775]\n",
      "step : 16, cost : 2.349337577819824, W : [0.99995613]\n",
      "step : 17, cost : 2.349102258682251, W : [0.9999766]\n",
      "step : 18, cost : 2.3489768505096436, W : [0.9999875]\n",
      "step : 19, cost : 2.348910093307495, W : [0.9999933]\n",
      "step : 20, cost : 2.34887433052063, W : [0.9999964]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1, 2, 3] # 입력값\n",
    "y_train = [1, 2, 3] # 결과값\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "# tf.random.normal([1]) : 랜덤값 지정 / name=\"Weight\" : 변수 이름지정\n",
    "b = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비(기본 단순 선형 모델)\n",
    "hypothesis = W * x_train + b\n",
    "\n",
    "# 비용함수 준비 # 실습슬라이드 p.7 중간식 참고\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))   \n",
    "\n",
    "# 최저비용학습을 위한 경사 하강 알고리즘(Gradient Descent Algorithm)\n",
    "    # Linear Regression cost 함수 최소화 강의슬라이드 참고\n",
    "    # Gradient descent algorithm(p.17) 공식\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * x_train - y_train)*x_train)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "# 알파값(learning_rate)은 파라미터 값, cost 줄이는 gradient 선택하기 \n",
    "# tensorflow에는 같은 변수에 바로 할당(W = W.ksjfkdf)할수없어서 assign 사용\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21) :\n",
    "    _, c, w = sess.run([update, cost, W])\n",
    "    # 제일 마지막 단계 update만 넣어주면 나머진 다 알아서 실행된다요오오오오오오옹로오\n",
    "    # 근데 cost랑 W 값 궁금하니까 얘네도 return해주세요 \n",
    "    #  _, c, w : update는 제외하고 c, w 값만 받아보자\n",
    "    print(\"step : {}, cost : {}, W : {}\".format(step, c, w))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 22.773441314697266, W : [0.69332623]\n",
      "step : 1, cost : 5.273974418640137, W : [0.92333156]\n",
      "step : 2, cost : 2.882951021194458, W : [0.9808329]\n",
      "step : 3, cost : 2.4091854095458984, W : [0.9952082]\n",
      "step : 4, cost : 2.2984933853149414, W : [0.99880207]\n",
      "step : 5, cost : 2.2713046073913574, W : [0.99970055]\n",
      "step : 6, cost : 2.2645373344421387, W : [0.99992514]\n",
      "step : 7, cost : 2.262847900390625, W : [0.9999813]\n",
      "step : 8, cost : 2.262425422668457, W : [0.99999535]\n",
      "step : 9, cost : 2.262319564819336, W : [0.9999988]\n",
      "step : 10, cost : 2.262293815612793, W : [0.9999997]\n",
      "step : 11, cost : 2.262287139892578, W : [0.99999994]\n",
      "step : 12, cost : 2.2622852325439453, W : [1.]\n",
      "step : 13, cost : 2.262284755706787, W : [1.]\n",
      "step : 14, cost : 2.262284755706787, W : [1.]\n",
      "step : 15, cost : 2.262284755706787, W : [1.]\n",
      "step : 16, cost : 2.262284755706787, W : [1.]\n",
      "step : 17, cost : 2.262284755706787, W : [1.]\n",
      "step : 18, cost : 2.262284755706787, W : [1.]\n",
      "step : 19, cost : 2.262284755706787, W : [1.]\n",
      "step : 20, cost : 2.262284755706787, W : [1.]\n",
      "step : 21, cost : 2.262284755706787, W : [1.]\n",
      "step : 22, cost : 2.262284755706787, W : [1.]\n",
      "step : 23, cost : 2.262284755706787, W : [1.]\n",
      "step : 24, cost : 2.262284755706787, W : [1.]\n",
      "step : 25, cost : 2.262284755706787, W : [1.]\n",
      "step : 26, cost : 2.262284755706787, W : [1.]\n",
      "step : 27, cost : 2.262284755706787, W : [1.]\n",
      "step : 28, cost : 2.262284755706787, W : [1.]\n",
      "step : 29, cost : 2.262284755706787, W : [1.]\n",
      "step : 30, cost : 2.262284755706787, W : [1.]\n",
      "step : 31, cost : 2.262284755706787, W : [1.]\n",
      "step : 32, cost : 2.262284755706787, W : [1.]\n",
      "step : 33, cost : 2.262284755706787, W : [1.]\n",
      "step : 34, cost : 2.262284755706787, W : [1.]\n",
      "step : 35, cost : 2.262284755706787, W : [1.]\n",
      "step : 36, cost : 2.262284755706787, W : [1.]\n",
      "step : 37, cost : 2.262284755706787, W : [1.]\n",
      "step : 38, cost : 2.262284755706787, W : [1.]\n",
      "step : 39, cost : 2.262284755706787, W : [1.]\n",
      "step : 40, cost : 2.262284755706787, W : [1.]\n",
      "step : 41, cost : 2.262284755706787, W : [1.]\n",
      "step : 42, cost : 2.262284755706787, W : [1.]\n",
      "step : 43, cost : 2.262284755706787, W : [1.]\n",
      "step : 44, cost : 2.262284755706787, W : [1.]\n",
      "step : 45, cost : 2.262284755706787, W : [1.]\n",
      "step : 46, cost : 2.262284755706787, W : [1.]\n",
      "step : 47, cost : 2.262284755706787, W : [1.]\n",
      "step : 48, cost : 2.262284755706787, W : [1.]\n",
      "step : 49, cost : 2.262284755706787, W : [1.]\n",
      "step : 50, cost : 2.262284755706787, W : [1.]\n",
      "step : 51, cost : 2.262284755706787, W : [1.]\n",
      "step : 52, cost : 2.262284755706787, W : [1.]\n",
      "step : 53, cost : 2.262284755706787, W : [1.]\n",
      "step : 54, cost : 2.262284755706787, W : [1.]\n",
      "step : 55, cost : 2.262284755706787, W : [1.]\n",
      "step : 56, cost : 2.262284755706787, W : [1.]\n",
      "step : 57, cost : 2.262284755706787, W : [1.]\n",
      "step : 58, cost : 2.262284755706787, W : [1.]\n",
      "step : 59, cost : 2.262284755706787, W : [1.]\n",
      "step : 60, cost : 2.262284755706787, W : [1.]\n",
      "step : 61, cost : 2.262284755706787, W : [1.]\n",
      "step : 62, cost : 2.262284755706787, W : [1.]\n",
      "step : 63, cost : 2.262284755706787, W : [1.]\n",
      "step : 64, cost : 2.262284755706787, W : [1.]\n",
      "step : 65, cost : 2.262284755706787, W : [1.]\n",
      "step : 66, cost : 2.262284755706787, W : [1.]\n",
      "step : 67, cost : 2.262284755706787, W : [1.]\n",
      "step : 68, cost : 2.262284755706787, W : [1.]\n",
      "step : 69, cost : 2.262284755706787, W : [1.]\n",
      "step : 70, cost : 2.262284755706787, W : [1.]\n",
      "step : 71, cost : 2.262284755706787, W : [1.]\n",
      "step : 72, cost : 2.262284755706787, W : [1.]\n",
      "step : 73, cost : 2.262284755706787, W : [1.]\n",
      "step : 74, cost : 2.262284755706787, W : [1.]\n",
      "step : 75, cost : 2.262284755706787, W : [1.]\n",
      "step : 76, cost : 2.262284755706787, W : [1.]\n",
      "step : 77, cost : 2.262284755706787, W : [1.]\n",
      "step : 78, cost : 2.262284755706787, W : [1.]\n",
      "step : 79, cost : 2.262284755706787, W : [1.]\n",
      "step : 80, cost : 2.262284755706787, W : [1.]\n",
      "step : 81, cost : 2.262284755706787, W : [1.]\n",
      "step : 82, cost : 2.262284755706787, W : [1.]\n",
      "step : 83, cost : 2.262284755706787, W : [1.]\n",
      "step : 84, cost : 2.262284755706787, W : [1.]\n",
      "step : 85, cost : 2.262284755706787, W : [1.]\n",
      "step : 86, cost : 2.262284755706787, W : [1.]\n",
      "step : 87, cost : 2.262284755706787, W : [1.]\n",
      "step : 88, cost : 2.262284755706787, W : [1.]\n",
      "step : 89, cost : 2.262284755706787, W : [1.]\n",
      "step : 90, cost : 2.262284755706787, W : [1.]\n",
      "step : 91, cost : 2.262284755706787, W : [1.]\n",
      "step : 92, cost : 2.262284755706787, W : [1.]\n",
      "step : 93, cost : 2.262284755706787, W : [1.]\n",
      "step : 94, cost : 2.262284755706787, W : [1.]\n",
      "step : 95, cost : 2.262284755706787, W : [1.]\n",
      "step : 96, cost : 2.262284755706787, W : [1.]\n",
      "step : 97, cost : 2.262284755706787, W : [1.]\n",
      "step : 98, cost : 2.262284755706787, W : [1.]\n",
      "step : 99, cost : 2.262284755706787, W : [1.]\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train 제대로 주어지지 않은 상태에서 데이터 예측\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None]) # shape : 몇개 데이터 넘겨줄지 알려줘야함 / None 1차원으로 넘겨줌\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비(기본 단순 선형 모델)\n",
    "hypothesis = W * x_train + b\n",
    "\n",
    "# 비용함수 준비 # 실습슬라이드 p.7 중간식 참고\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))   \n",
    "\n",
    "# 최저비용학습을 위한 경사 하강 알고리즘(Gradient Descent Algorithm)\n",
    "    # Linear Regression cost 함수 최소화 강의슬라이드 참고\n",
    "    # Gradient descent algorithm(p.17) 공식\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * x_train - y_train)*x_train)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "# 알파값(learning_rate)은 파라미터 값, cost 줄이는 gradient 선택하기 \n",
    "# tensorflow에는 같은 변수에 바로 할당(W = W.ksjfkdf)할수없어서 assign 사용\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100) :\n",
    "    _, c, w = sess.run([update, cost, W], feed_dict={x_train:[1, 2, 3, 4], y_train:[1, 2, 3, 4]}) # x_train에는 4개의 값 넘겨주기 \n",
    "    # 제일 마지막 단계 update만 넣어주면 나머진 다 알아서 실행된다요오오오오오오옹로오\n",
    "    # 근데 cost랑 W 값 궁금하니까 얘네도 return해주세요 \n",
    "    #  _, c, w : update는 제외하고 c, w 값만 받아보자\n",
    "    print(\"step : {}, cost : {}, W : {}\".format(step, c, w))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 1.1947587728500366, W : [0.66248393]\n",
      "step : 1, cost : 0.8296979665756226, W : [0.7123737]\n",
      "step : 2, cost : 0.5763856768608093, W : [0.7539509]\n",
      "step : 3, cost : 0.4006136655807495, W : [0.7886038]\n",
      "step : 4, cost : 0.27864524722099304, W : [0.81748873]\n",
      "step : 5, cost : 0.19400988519191742, W : [0.84156895]\n",
      "step : 6, cost : 0.13527919352054596, W : [0.8616468]\n",
      "step : 7, cost : 0.09452325850725174, W : [0.87839055]\n",
      "step : 8, cost : 0.06623974442481995, W : [0.8923571]\n",
      "step : 9, cost : 0.04661041498184204, W : [0.9040101]\n",
      "step : 10, cost : 0.03298626095056534, W : [0.913736]\n",
      "step : 11, cost : 0.023528777062892914, W : [0.9218564]\n",
      "step : 12, cost : 0.016962707042694092, W : [0.92863953]\n",
      "step : 13, cost : 0.012402765452861786, W : [0.9343086]\n",
      "step : 14, cost : 0.009234962053596973, W : [0.93904954]\n",
      "step : 15, cost : 0.007033143192529678, W : [0.9430174]\n",
      "step : 16, cost : 0.005501613020896912, W : [0.9463412]\n",
      "step : 17, cost : 0.004435183946043253, W : [0.94912845]\n",
      "step : 18, cost : 0.0036915361415594816, W : [0.9514687]\n",
      "step : 19, cost : 0.0031718448735773563, W : [0.95343655]\n",
      "step : 20, cost : 0.0028076008893549442, W : [0.9550941]\n"
     ]
    }
   ],
   "source": [
    "# 경사하강알고리즘 자체를 해주는 객체 사용\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None]) # shape : 몇개 데이터 넘겨줄지 알려줘야함 / None 1차원으로 넘겨줌\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비(기본 단순 선형 모델)\n",
    "hypothesis = W * x_train + b\n",
    "\n",
    "# 비용함수 준비 # 실습슬라이드 p.7 중간식 참고\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))   \n",
    "\n",
    "# 최저비용학습을 위한 경사 하강 알고리즘(Gradient Descent Algorithm)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)# minimize 에 가설 공식 넣어주면 됨\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21) :\n",
    "    _, c, w = sess.run([train, cost, W], feed_dict={x_train:[1, 2, 3, 4], y_train:[1, 2, 3, 4]}) # x_train에는 4개의 값 넘겨주기 \n",
    "    # 제일 마지막 단계 update만 넣어주면 나머진 다 알아서 실행된다요오오오오오오옹로오\n",
    "    # 근데 cost랑 W 값 궁금하니까 얘네도 return해주세요 \n",
    "    #  _, c, w : update는 제외하고 c, w 값만 받아보자\n",
    "    print(\"step : {}, cost : {}, W : {}\".format(step, c, w))\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 9.969096183776855, W : [0.3778319], bias : [0.7219428]\n",
      "step : 100, cost : 0.003398333443328738, W : [1.037719], bias : [0.9638223]\n",
      "step : 200, cost : 0.0017262387555092573, W : [1.026883], bias : [1.0029436]\n",
      "step : 300, cost : 0.0008768863044679165, W : [1.01916], bias : [1.030826]\n",
      "step : 400, cost : 0.00044543101103045046, W : [1.0136558], bias : [1.0506982]\n",
      "step : 500, cost : 0.000226268355618231, W : [1.0097327], bias : [1.0648613]\n",
      "step : 600, cost : 0.0001149408271885477, W : [1.0069369], bias : [1.0749557]\n",
      "step : 700, cost : 5.838323340867646e-05, W : [1.0049438], bias : [1.0821508]\n",
      "step : 800, cost : 2.9657454433618113e-05, W : [1.0035236], bias : [1.0872784]\n",
      "step : 900, cost : 1.5063315004226752e-05, W : [1.0025114], bias : [1.0909333]\n",
      "step : 1000, cost : 7.651731721125543e-06, W : [1.0017899], bias : [1.0935379]\n",
      "step : 1100, cost : 3.8863063309690915e-06, W : [1.0012757], bias : [1.0953946]\n",
      "step : 1200, cost : 1.9740641619137023e-06, W : [1.0009092], bias : [1.0967176]\n",
      "step : 1300, cost : 1.0033041917267838e-06, W : [1.0006481], bias : [1.0976601]\n",
      "step : 1400, cost : 5.095937467558542e-07, W : [1.000462], bias : [1.098332]\n",
      "step : 1500, cost : 2.591003180896223e-07, W : [1.0003295], bias : [1.0988107]\n",
      "step : 1600, cost : 1.317547457801993e-07, W : [1.0002348], bias : [1.0991518]\n",
      "step : 1700, cost : 6.703245247763334e-08, W : [1.0001675], bias : [1.0993949]\n",
      "step : 1800, cost : 3.4100320789320904e-08, W : [1.0001196], bias : [1.0995685]\n",
      "step : 1900, cost : 1.7435240806662478e-08, W : [1.0000854], bias : [1.0996917]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None]) # shape : 몇개 데이터 넘겨줄지 알려줘야함 / None 1차원으로 넘겨줌\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비(기본 단순 선형 모델)\n",
    "hypothesis = W * x_train + b\n",
    "\n",
    "# 비용함수 준비 # 실습슬라이드 p.7 중간식 참고\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))   \n",
    "\n",
    "# 최저비용학습을 위한 경사 하강 알고리즘(Gradient Descent Algorithm)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost) # minimize 에 가설 공식 넣어주면 됨\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000) :\n",
    "    _, curr_c, curr_w, curr_b = sess.run([train, cost, W, b], feed_dict={x_train:[1, 2, 3, 4, 5],\n",
    "                                                    y_train:[2.1, 3.1, 4.1, 5.1, 6.1]}) # x_train에는 4개의 값 넘겨주기 \n",
    "    \n",
    "    if step % 100 == 0: # 2000번 너무 많으니까 걍 100번에 한번 찍히도록\n",
    "        print(\"step : {}, cost : {}, W : {}, bias : {}\".format(step, curr_c, curr_w, curr_b))\n",
    "        \n",
    "# session 계속 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.101427]\n",
      "[3.5999317 4.800005 ]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(sess.run(hypothesis, feed_dict={x_train:[27]}))\n",
    "print(sess.run(hypothesis, feed_dict={x_train:[2.5, 3.7]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, hypothesis : [-0.7621369 -0.918597  -1.0750571 -1.2315173 -1.3879775 -1.5444376\n",
      " -1.7008977], cost : 13455145984.0\n",
      "step : 500, hypothesis : [ 29443.41   54486.055  79528.7   104571.34  129613.984 154656.64\n",
      " 179699.28 ], cost : 10400110.0\n",
      "step : 1000, hypothesis : [ 29028.521  54176.156  79323.8   104471.42  129619.06  154766.7\n",
      " 179914.33 ], cost : 9835889.0\n",
      "step : 1500, hypothesis : [ 28686.2    53920.453  79154.71  104388.96  129623.21  154857.47\n",
      " 180091.72 ], cost : 9451773.0\n",
      "step : 2000, hypothesis : [ 28403.76  53709.48  79015.2  104320.92 129626.64 154932.38 180238.1 ], cost : 9190289.0\n",
      "step : 2500, hypothesis : [ 28170.723  53535.406  78900.086 104264.77  129629.46  154994.14\n",
      " 180358.83 ], cost : 9012278.0\n",
      "step : 3000, hypothesis : [ 27978.453  53391.785  78805.12  104218.445 129631.77  155045.12\n",
      " 180458.45 ], cost : 8891104.0\n",
      "step : 3500, hypothesis : [ 27819.82   53273.293  78726.766 104180.24  129633.72  155087.19\n",
      " 180540.67 ], cost : 8808604.0\n",
      "step : 4000, hypothesis : [ 27688.934  53175.523  78662.11  104148.7   129635.3   155121.88\n",
      " 180608.47 ], cost : 8752441.0\n",
      "step : 4500, hypothesis : [ 27580.951  53094.875  78608.8   104122.72  129636.64  155150.56\n",
      " 180664.48 ], cost : 8714209.0\n",
      "step : 5000, hypothesis : [ 27491.842  53028.297  78564.75  104101.2   129637.66  155174.12\n",
      " 180710.58 ], cost : 8688185.0\n",
      "step : 5500, hypothesis : [ 27418.332  52973.4    78528.46  104083.52  129638.586 155193.66\n",
      " 180748.72 ], cost : 8670461.0\n",
      "step : 6000, hypothesis : [ 27357.674  52928.086  78498.49  104068.91  129639.32  155209.73\n",
      " 180780.16 ], cost : 8658397.0\n",
      "step : 6500, hypothesis : [ 27307.637  52890.715  78473.79  104056.87  129639.945 155223.03\n",
      " 180806.11 ], cost : 8650183.0\n",
      "step : 7000, hypothesis : [ 27266.354  52859.89   78453.42  104046.96  129640.5   155234.03\n",
      " 180827.58 ], cost : 8644589.0\n",
      "step : 7500, hypothesis : [ 27232.254  52834.39   78436.52  104038.66  129640.79  155242.94\n",
      " 180845.06 ], cost : 8640782.0\n",
      "step : 8000, hypothesis : [ 27204.164  52813.44   78422.72  104031.99  129641.266 155250.55\n",
      " 180859.81 ], cost : 8638186.0\n",
      "step : 8500, hypothesis : [ 27180.957  52796.098  78411.234 104026.375 129641.516 155256.64\n",
      " 180871.78 ], cost : 8636416.0\n",
      "step : 9000, hypothesis : [ 27161.816  52781.8    78401.78  104021.766 129641.75  155261.73\n",
      " 180881.72 ], cost : 8635220.0\n",
      "step : 9500, hypothesis : [ 27146.041  52770.03   78394.02  104018.016 129642.01  155265.98\n",
      " 180889.98 ], cost : 8634399.0\n"
     ]
    }
   ],
   "source": [
    "# 아래의 데이터를 가지고 하루 8시간을 일했을 때 매출액이 얼마인지 예측하시오.\n",
    "x_data = [1, 2, 3, 4, 5, 6, 7] # 7시간 일했을때까지\n",
    "y_data = [25000, 55000, 75000, 110000, 128000, 155000, 180000] # 각각의 매출액이 얼마인가\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random.normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "hypo = W * X + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypo - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10000) :\n",
    "    _, curr_h, curr_c = sess.run([train, hypo, cost], feed_dict={X:x_data, y:y_data})\n",
    "    \n",
    "    if step % 500 == 0:        \n",
    "        print(\"step : {}, hypothesis : {}, cost : {}\".format(step, curr_h, curr_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206523.78]\n"
     ]
    }
   ],
   "source": [
    "# 8시간 일했을 때의 매출액 알기\n",
    "print(sess.run(hypo, feed_dict={X:[8]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 선형 회귀모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러개의 입력의 Linear Regression  강의슬라이드, lab슬라이드 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 3160.19189453125, hypothesis : [196.37163 247.84644 238.23853 259.26968 191.8765 ]\n",
      "step : 100, cost : 10.93991470336914, hypothesis : [146.71205 187.91507 179.31421 195.08775 146.11546]\n",
      "step : 200, cost : 10.373735427856445, hypothesis : [146.83801 187.82875 179.35283 195.11542 146.00243]\n",
      "step : 300, cost : 9.837379455566406, hypothesis : [146.96062 187.74472 179.39043 195.14233 145.89241]\n",
      "step : 400, cost : 9.329366683959961, hypothesis : [147.07994 187.66295 179.42702 195.16853 145.78535]\n",
      "step : 500, cost : 8.84810733795166, hypothesis : [147.19608 187.58334 179.46265 195.19398 145.68114]\n",
      "step : 600, cost : 8.392243385314941, hypothesis : [147.30911 187.50586 179.4973  195.21878 145.57973]\n",
      "step : 700, cost : 7.960448265075684, hypothesis : [147.41914 187.4305  179.53107 195.2429  145.48103]\n",
      "step : 800, cost : 7.55142068862915, hypothesis : [147.52625 187.35712 179.56392 195.2664  145.38501]\n",
      "step : 900, cost : 7.163971900939941, hypothesis : [147.63046 187.28569 179.59589 195.28922 145.29152]\n",
      "step : 1000, cost : 6.796971321105957, hypothesis : [147.7319  187.21619 179.62701 195.31145 145.20055]\n",
      "step : 1100, cost : 6.449307918548584, hypothesis : [147.83064 187.14851 179.65729 195.33307 145.11201]\n",
      "step : 1200, cost : 6.120002746582031, hypothesis : [147.92674 187.08267 179.68677 195.3541  145.02585]\n",
      "step : 1300, cost : 5.808054447174072, hypothesis : [148.02028 187.01859 179.71545 195.37457 144.94199]\n",
      "step : 1400, cost : 5.512570858001709, hypothesis : [148.11131 186.95619 179.7434  195.39449 144.86038]\n",
      "step : 1500, cost : 5.232680320739746, hypothesis : [148.1999  186.89548 179.77057 195.41386 144.78094]\n",
      "step : 1600, cost : 4.967539310455322, hypothesis : [148.28616 186.8364  179.79704 195.43272 144.70366]\n",
      "step : 1700, cost : 4.7164082527160645, hypothesis : [148.37009 186.77888 179.82277 195.45105 144.62842]\n",
      "step : 1800, cost : 4.478509902954102, hypothesis : [148.4518  186.72292 179.84785 195.4689  144.55522]\n",
      "step : 1900, cost : 4.253139972686768, hypothesis : [148.53131 186.66841 179.87224 195.48628 144.48396]\n"
     ]
    }
   ],
   "source": [
    "# 단순하게 처리하는 경우\n",
    "\n",
    "X1 = tf.placeholder(tf.float32, shape=[None])\n",
    "X2 = tf.placeholder(tf.float32, shape=[None])\n",
    "X3 = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([1]))\n",
    "W2 = tf.Variable(tf.random_normal([1]))\n",
    "W3 = tf.Variable(tf.random_normal([1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# 가설 설정\n",
    "hypothesis = W1*X1 + W2*X2 + W3*X3 + b\n",
    "\n",
    "# 비용함수\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "# 최소 비용 계산\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "with tf.Session() as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2000) :\n",
    "        _, hy, co = sess.run([train, hypothesis, cost], feed_dict={X1:x1_data, X2:x2_data, X3:x3_data, y:y_data})\n",
    "        if step % 100 == 0: \n",
    "            print(\"step : {}, cost : {}, hypothesis : {}\".format(step, co, hy))\n",
    "            # hypothesis 결과값이 실제 결과값 y_data 와 비슷한지 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, cost : 60519.35546875, hypothesis : [[-68.44322 ]\n",
      " [-76.32652 ]\n",
      " [-78.084915]\n",
      " [-87.8255  ]\n",
      " [-54.32952 ]]\n",
      "step : 100, cost : 4.92209005355835, hypothesis : [[149.90068]\n",
      " [185.97198]\n",
      " [180.43182]\n",
      " [193.69054]\n",
      " [145.70654]]\n",
      "step : 200, cost : 4.732911586761475, hypothesis : [[149.9697 ]\n",
      " [185.92413]\n",
      " [180.45229]\n",
      " [193.71077]\n",
      " [145.63913]]\n",
      "step : 300, cost : 4.553365707397461, hypothesis : [[150.03683]\n",
      " [185.87756]\n",
      " [180.47215]\n",
      " [193.73058]\n",
      " [145.57344]]\n",
      "step : 400, cost : 4.3830342292785645, hypothesis : [[150.10211]\n",
      " [185.83228]\n",
      " [180.49146]\n",
      " [193.74994]\n",
      " [145.50945]]\n",
      "step : 500, cost : 4.221369743347168, hypothesis : [[150.16557]\n",
      " [185.78821]\n",
      " [180.5102 ]\n",
      " [193.7689 ]\n",
      " [145.44708]]\n",
      "step : 600, cost : 4.0679030418396, hypothesis : [[150.22726]\n",
      " [185.74535]\n",
      " [180.52838]\n",
      " [193.78746]\n",
      " [145.38628]]\n",
      "step : 700, cost : 3.922281265258789, hypothesis : [[150.28728]\n",
      " [185.70369]\n",
      " [180.5461 ]\n",
      " [193.80565]\n",
      " [145.32707]]\n",
      "step : 800, cost : 3.784053087234497, hypothesis : [[150.3456 ]\n",
      " [185.66316]\n",
      " [180.56328]\n",
      " [193.82344]\n",
      " [145.26936]]\n",
      "step : 900, cost : 3.652791976928711, hypothesis : [[150.40233]\n",
      " [185.62373]\n",
      " [180.57997]\n",
      " [193.84087]\n",
      " [145.21312]]\n",
      "step : 1000, cost : 3.5281829833984375, hypothesis : [[150.45747]\n",
      " [185.5854 ]\n",
      " [180.59618]\n",
      " [193.85793]\n",
      " [145.15831]]\n",
      "step : 1100, cost : 3.4098713397979736, hypothesis : [[150.51108]\n",
      " [185.54811]\n",
      " [180.61191]\n",
      " [193.87463]\n",
      " [145.1049 ]]\n",
      "step : 1200, cost : 3.2974905967712402, hypothesis : [[150.56319]\n",
      " [185.51186]\n",
      " [180.62721]\n",
      " [193.89102]\n",
      " [145.05284]]\n",
      "step : 1300, cost : 3.1907572746276855, hypothesis : [[150.61386]\n",
      " [185.47658]\n",
      " [180.64203]\n",
      " [193.90703]\n",
      " [145.00209]]\n",
      "step : 1400, cost : 3.0893492698669434, hypothesis : [[150.6631 ]\n",
      " [185.44228]\n",
      " [180.65643]\n",
      " [193.92273]\n",
      " [144.9526 ]]\n",
      "step : 1500, cost : 2.993046283721924, hypothesis : [[150.71097]\n",
      " [185.40894]\n",
      " [180.67041]\n",
      " [193.93811]\n",
      " [144.9044 ]]\n",
      "step : 1600, cost : 2.9015238285064697, hypothesis : [[150.75752]\n",
      " [185.37651]\n",
      " [180.684  ]\n",
      " [193.9532 ]\n",
      " [144.85742]]\n",
      "step : 1700, cost : 2.814513683319092, hypothesis : [[150.80275]\n",
      " [185.34494]\n",
      " [180.69716]\n",
      " [193.96797]\n",
      " [144.81158]]\n",
      "step : 1800, cost : 2.7318599224090576, hypothesis : [[150.84671]\n",
      " [185.31429]\n",
      " [180.70996]\n",
      " [193.98248]\n",
      " [144.76695]]\n",
      "step : 1900, cost : 2.6532700061798096, hypothesis : [[150.88943]\n",
      " [185.28445]\n",
      " [180.72238]\n",
      " [193.99667]\n",
      " [144.7234 ]]\n",
      "step : 2000, cost : 2.5785603523254395, hypothesis : [[150.93098]\n",
      " [185.25546]\n",
      " [180.73444]\n",
      " [194.01059]\n",
      " [144.68097]]\n"
     ]
    }
   ],
   "source": [
    "### Matrix로 처리하는 경우\n",
    "\n",
    "x_data = [[73., 80., 75.], [93., 88., 93.],\n",
    "         [89., 91., 90.], [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3]) # ?개로 입력되서 3개로 나옴\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1])) # 위에 X에 5,3 행렬에서 가져올거 3 ([5, 3] * [3, 1])\n",
    "b = tf.Variable(tf.random_normal([1])) # 마지막 y로 출력하는 개수 1 (위에 [3, 1]에서의 1)\n",
    "\n",
    "# 가설 설정\n",
    "hypothesis = tf.matmul(X, W) + b # X, W 행렬곱으로 계산하기\n",
    "\n",
    "# 비용함수\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "# 최소 비용 계산\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "##################### Graph 작업 완료\n",
    "\n",
    "with tf.Session() as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001) :\n",
    "        _, hy, co = sess.run([train, hypothesis, cost], feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "        if step % 100 == 0: \n",
    "            print(\"step : {}, cost : {}, hypothesis : {}\".format(step, co, hy))\n",
    "            # hypothesis 결과값이 실제 결과값 y_data 와 비슷한지 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DASK\n",
    "    - 가상 데이터프레임\n",
    "    - 병렬처리용 작업 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/sample1.csv\n"
     ]
    }
   ],
   "source": [
    "# 파일 생성 & 저장\n",
    "\n",
    "%%writefile \"data/sample1.csv\"\n",
    "c1, c2, c3\n",
    "1, 1.11, one\n",
    "2, 2.22, two\n",
    "3, 3.33, three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.22"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 가져오기\n",
    "\n",
    "df1 = pd.read_csv(\"data/sample1.csv\")\n",
    "df1 # 자동적으로 dataframe형식으로 가져옴 \n",
    "\n",
    "\n",
    "df1[\" c2\"].mean() # 컬럼이름앞에 공백있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 3 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                  c1       c2      c3\n",
       "npartitions=1                        \n",
       "               int64  float64  object\n",
       "                 ...      ...     ...\n",
       "Dask Name: from-delayed, 3 tasks"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dask를 이용해보자\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df2 = dd.read_csv(\"data/sample1.csv\")\n",
    "df2 # 실제 데이터 값은 안올라오고 틀만 나타남 / Dask Name: from-delayed, 3 tasks : 데이터를 한번에 불러오고있지 않고있어요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:5916: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3\n",
       "0   1  1.11     one\n",
       "1   2  2.22     two\n",
       "2   3  3.33   three"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() # 필요할때 데이터를 가져와서 쓸수있게끔 해줘요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.22"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\" c2\"].mean() # 객체는 생성되어있는데 값이 보이진 않아요...\n",
    "df2[\" c2\"].mean().compute() # 값을 보고싶다면 compute!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = dd.read_csv(\"data/crime.csv\", dtype=str, error_bad_lines=False, warn_bad_lines=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.9s\n",
      "[########################################] | 100% Completed |  1.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                            171179\n",
       "Case Number                   171179\n",
       "Date                          171179\n",
       "Block                         171179\n",
       "IUCR                          171179\n",
       "Primary Type                  171179\n",
       "Description                   171179\n",
       "Location Description          170591\n",
       "Arrest                        171179\n",
       "Domestic                      171179\n",
       "Beat                          171178\n",
       "District                      171178\n",
       "Ward                          171171\n",
       "Community Area                171178\n",
       "FBI Code                      171178\n",
       "X Coordinate                  170221\n",
       "Y Coordinate                  170221\n",
       "Year                          171178\n",
       "Updated On                    171178\n",
       "Latitude                      170221\n",
       "Longitude                     170221\n",
       "Location                      170221\n",
       "Historical Wards 2003-2015    169683\n",
       "Zip Codes                     170221\n",
       "Community Areas               169754\n",
       "Census Tracts                 169770\n",
       "Wards                         169755\n",
       "Boundaries - ZIP Codes        169755\n",
       "Police Districts              169769\n",
       "Police Beats                  169769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3\n",
    "df3.tail()\n",
    "df3.count().compute() # 전체데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1.3s\n",
      "[########################################] | 100% Completed |  1.4s\n",
      "Wall time: 1.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                            228750\n",
       "Case Number                   228750\n",
       "Date                          228750\n",
       "Block                         228750\n",
       "IUCR                          228750\n",
       "Primary Type                  228750\n",
       "Description                   228749\n",
       "Location Description          227938\n",
       "Arrest                        228749\n",
       "Domestic                      228749\n",
       "Beat                          228749\n",
       "District                      228749\n",
       "Ward                          228742\n",
       "Community Area                228748\n",
       "FBI Code                      228749\n",
       "X Coordinate                  226295\n",
       "Y Coordinate                  226295\n",
       "Year                          228749\n",
       "Updated On                    228749\n",
       "Latitude                      226295\n",
       "Longitude                     226295\n",
       "Location                      226295\n",
       "Historical Wards 2003-2015    225562\n",
       "Zip Codes                     226295\n",
       "Community Areas               225654\n",
       "Census Tracts                 225696\n",
       "Wards                         225656\n",
       "Boundaries - ZIP Codes        225655\n",
       "Police Districts              225682\n",
       "Police Beats                  225682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df3.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2.1s\n",
      "[########################################] | 100% Completed |  2.2s\n",
      "Wall time: 2.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                            241329\n",
       "Case Number                   241329\n",
       "Date                          241329\n",
       "Block                         241329\n",
       "IUCR                          241329\n",
       "Primary Type                  241329\n",
       "Description                   241329\n",
       "Location Description          240475\n",
       "Arrest                        241329\n",
       "Domestic                      241329\n",
       "Beat                          241329\n",
       "District                      241329\n",
       "Ward                          241321\n",
       "Community Area                241328\n",
       "FBI Code                      241329\n",
       "X Coordinate                  238643\n",
       "Y Coordinate                  238643\n",
       "Year                          241329\n",
       "Updated On                    241329\n",
       "Latitude                      238643\n",
       "Longitude                     238643\n",
       "Location                      238643\n",
       "Historical Wards 2003-2015    237868\n",
       "Zip Codes                     238643\n",
       "Community Areas               237965\n",
       "Census Tracts                 238014\n",
       "Wards                         237967\n",
       "Boundaries - ZIP Codes        237966\n",
       "Police Districts              237994\n",
       "Police Beats                  237994\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df3.count().compute(scheduler=\"processes\", num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    6\n",
       "2    9\n",
       "Name: c1, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df2[\"c1\"] * 3).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.assign(c1=df2[\"c1\"]-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:5916: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3\n",
       "0  -2  1.11     one\n",
       "1  -1  2.22     two\n",
       "2   0  3.33   three"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:5916: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "      <td>-2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "      <td>-1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3 title\n",
       "0  -2  1.11     one   -2%\n",
       "1  -1  2.22     two   -1%\n",
       "2   0  3.33   three    0%"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 컬럼 추가\n",
    "df2 = df2.assign(title=df2[\"c1\"].astype(str) + \"%\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복수 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/sample2.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'data/sample2.csv'\n",
    "c1, c2, c3\n",
    "4, 4.11, one\n",
    "5, 5.22, two\n",
    "6, 6.33, three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c1     6\n",
       " c2    6\n",
       " c3    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복수데이터\n",
    "df4 = dd.read_csv(\"data/sample*.csv\")\n",
    "df4.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"data/data-01-test-score1.csv\"])\n",
    "key, value = tf.TextLineReader().read(filename_queue)\n",
    "xy = tf.decode_csv(value, record_defaults=[[0,], [0,], [0,], [0,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'DecodeCSV_1:0' shape=() dtype=int32>,\n",
       " <tf.Tensor 'DecodeCSV_1:1' shape=() dtype=int32>,\n",
       " <tf.Tensor 'DecodeCSV_1:2' shape=() dtype=int32>,\n",
       " <tf.Tensor 'DecodeCSV_1:3' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.train.batch\n",
    "\n",
    "    - Batch : 전체 데이터 일괄처리 (메모리 충분할시에 사용)\n",
    "    - Stochastic : 한개의 데이터\n",
    "    - Mini Batch : Batch와 Stochastic의 절충안 (적당한 개수 지정)\n",
    "    \n",
    "    + epoch : 전체 셋에 대해 한 번 학습을 완료한 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10) \n",
    "# xy[0:-1] : 0부터 마지막까지 / 독립변수,  xy[-1:] : 뒤에서부터 / 종속변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3]) \n",
    "    # ?개의 데이터(몇개가 들어올지 모르니)가 3개의 특성으로 나누어지기\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1])) \n",
    "b = tf.Variable(tf.random_normal([1])) # W에서 출력의 개수 \n",
    "\n",
    "# 가설\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 성적은 : [[195.84616]]\n",
      "다른사람의 성적은 : [[187.08548]\n",
      " [169.91528]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for step in range(2001) :\n",
    "        x_batch, y_batch =  sess.run([train_x_batch, train_y_batch])\n",
    "        sess.run(train, feed_dict={X:x_batch, y:y_batch})\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    # thread : 프로세스 안에서 실행되는 작업 단위\n",
    "    # multi thread : 동시에 여러개의 thread 실행\n",
    "    # scheduling : 여러개의 thread를 어떤 순서에 의해 동시에 실행할것인지 결정하는것\n",
    "    #            : 여러 thread들이 아주 짧은 시간동안 번갈아가면서 thread의 run()메소드를 조금씩 실행하는거\n",
    "    # join : thread 여러개 시행될때 끝나지 않은 thread를 기다렸다가 같이 끝나게 하는 메서드\n",
    "    \n",
    "    print(\"당신의 성적은 :\", sess.run(hypothesis, feed_dict={X:[[100, 70, 101]]}))\n",
    "    print(\"다른사람의 성적은 :\", sess.run(hypothesis, feed_dict={X:[[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀모델\n",
    "http://hunkim.github.io/ml/lec5.pdf  logistic 강의 슬라이드 참고\n",
    "\n",
    "Logistic Hypothesis 공식(=sigmoid 공식): H(X) = 1/(1+e^(-WX))\n",
    "\n",
    "Cost function 공식 : C(H(x), y) = ylog(H(x)) - (1-y)log(1-H(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 작업\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2]) # x_data 6개에 2개씩 묶여있으므로\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# 가설 설정\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b) # 선형회귀 공식에 sigmoid 함수 감싸주기 \n",
    "\n",
    "# 비용 함수\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis) + (1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X:x_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 검증\n",
    "pred = tf.cast(hypothesis > 0.5, dtype=tf.float32) \n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가설 :  [[0.02220011]\n",
      " [0.1453554 ]\n",
      " [0.26093423]\n",
      " [0.8022406 ]\n",
      " [0.95195085]\n",
      " [0.98439515]] \n",
      "예측 : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "h, p, a = sess.run([hypothesis, pred, accuracy], feed_dict={X:x_data, y:y_data})\n",
    "print(\"가설 : \", h, \"\\n예측 :\", p, \"\\n정확도 :\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "softmax Regression 강의슬라이드, 실습슬라이드 참고\n",
    "\n",
    "Sigmoid로 나온 결과값을 0과 1사이의 확률로 계산하여 제공\n",
    "\n",
    "one-hot encoding(하나의 값에만 1의 값(ex 최대값)을 주고 나머지 다 0) 사용 가능 : 구별하기 쉬움\n",
    "\n",
    "Cross-Entropy : 복잡함 최소화 시켜주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27011934 0.72591513 0.00396553]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비 \n",
    "x_data = [[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7]] \n",
    "\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# 훈련\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "\n",
    "# 가설 설정\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(train, feed_dict={X:x_data, y:y_data})\n",
    "    # 훈련 종료\n",
    "    \n",
    "    result = sess.run(hypothesis, feed_dict={X:[[1, 11, 7, 9]]})\n",
    "    print(result)\n",
    "    print(sess.run(tf.arg_max(result, 1))) # 가장 큰값 꺼내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Softmax : softmax_corss_entropy_with_logits(), one_hot(), reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.724456e-02 9.427342e-01 2.127027e-05]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 훈련\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# 가설 설정\n",
    "logit = tf.matmul(X, W) + b  # logit : WX + b (원초적 공식)\n",
    "hypothesis = tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y_data) \n",
    "                                                # logits= : 식이 뭐냥, labels= :정답은 뭐냥\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(train, feed_dict={X:x_data, y:y_data})\n",
    "    # 훈련 종료\n",
    "    \n",
    "    result = sess.run(hypothesis, feed_dict={X:[[1, 11, 7, 9]]})\n",
    "    print(result)\n",
    "    print(sess.run(tf.arg_max(result, 1))) # 가장 큰값 꺼내기\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝의 기본 개념과 문제 실습슬라이드(tensor manipulation) 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot\n",
    "sess = tf.Session()\n",
    "tf.one_hot([[0], [1], [2], [0]], depth=3).eval(session=sess)\n",
    "        # depth = 3 : 3개로 구분\n",
    "        # 넘겨준 값에 대해 차원을 하나 더 추가하여 결과를 뽑아낸다\n",
    "        # 그래서 reshape 이용해서 원하는 차원으로 바꿔주기이이이\n",
    "\n",
    "## 원하는 차원으로까지 바꿔주기\n",
    "t = tf.one_hot([[0], [1], [2], [0]], depth=3)\n",
    "tf.reshape(t, shape=[-1, 3]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례1 : 동물 분류 예측\n",
    "\n",
    "컬럼 Q : 동물 결과  /  나머지 컬럼들 : 동물의 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비 \n",
    "xy = np.loadtxt(\"data/data-04-zoo.csv\", delimiter=\",\", dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "xy.shape # shape 어찌 지정할지 알아보기위해 출력해보자\n",
    "\n",
    "# 훈련\n",
    "X = tf.placeholder(tf.float32, shape=[None, 16])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 1]) # 0-6까지 총 7가지 종류가 나옴\n",
    "\n",
    "# one-hot encoding\n",
    "y_one_hot = tf.one_hot(y,7) \n",
    "    # 이렇게 하면 출력값이 한개에서 갑자기 7개로 늘어난다.  그래서 밑에 가중치와 바이어스를 고쳐야함\n",
    "y_one_hot = tf.reshape(y_one_hot, shape=[-1, 7])\n",
    "    # 위에 값이 3차원으로 바뀌기 때문에 2차원으로 수정해야함.\n",
    "    # 열이 7이고 행은 알아서 하세요\n",
    "\n",
    "# W, b 준비\n",
    "W = tf.Variable(tf.random_normal([16, 7])) # one-hot에서 출력값 7개로 늘렸으니 원래는 [16, 1]인데 [16, 7]로 해주기\n",
    "b = tf.Variable(tf.random_normal([7]))\n",
    "\n",
    "# 가설 설정\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.argmax(hypothesis, 1)\n",
    "correct_pred = tf.equal(pred, tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 9.432\tAcc: 41.58%\n",
      "Step:   100\tLoss: 0.003\tAcc: 100.00%\n",
      "Step:   200\tLoss: 0.002\tAcc: 100.00%\n",
      "Step:   300\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   400\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   500\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   600\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   700\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   800\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:   900\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:  1000\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:  1100\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:  1200\tLoss: 0.001\tAcc: 100.00%\n",
      "Step:  1300\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1400\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1500\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1600\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1700\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1800\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  1900\tLoss: 0.000\tAcc: 100.00%\n",
      "Step:  2000\tLoss: 0.000\tAcc: 100.00%\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 4 True Y:4\n",
      "[True] prediction : 4 True Y:4\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 4 True Y:4\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 2 True Y:2\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 2 True Y:2\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 2 True Y:2\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 4 True Y:4\n",
      "[True] prediction : 2 True Y:2\n",
      "[True] prediction : 2 True Y:2\n",
      "[True] prediction : 3 True Y:3\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 1 True Y:1\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 5 True Y:5\n",
      "[True] prediction : 0 True Y:0\n",
      "[True] prediction : 6 True Y:6\n",
      "[True] prediction : 1 True Y:1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, y:y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            loss, acc = sess.run([tf.reduce_mean(cost), accuracy], feed_dict={X:x_data, y:y_data})\n",
    "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "            \n",
    "    pred = sess.run(pred, feed_dict={X:x_data})\n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] prediction : {} True Y:{}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례2 : MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-91728e189d13>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\acorn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)\n",
    "dir(mnist)\n",
    "mnist.train.labels\n",
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "logit = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logit)\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 18.683\tAcc: 6.00%\n",
      "Step:     0\tLoss: 30.249\tAcc: 31.00%\n",
      "Step:     0\tLoss: 48.237\tAcc: 37.00%\n",
      "Step:     0\tLoss: 39.402\tAcc: 37.00%\n",
      "Step:     0\tLoss: 34.353\tAcc: 34.00%\n",
      "Step:     0\tLoss: 31.700\tAcc: 26.00%\n",
      "Step:     0\tLoss: 46.364\tAcc: 37.00%\n",
      "Step:     0\tLoss: 29.326\tAcc: 20.00%\n",
      "Step:     0\tLoss: 27.572\tAcc: 55.00%\n",
      "Step:     0\tLoss: 23.124\tAcc: 57.00%\n",
      "Step:     0\tLoss: 15.586\tAcc: 65.00%\n",
      "Step:     0\tLoss: 15.817\tAcc: 58.00%\n",
      "Step:     0\tLoss: 16.816\tAcc: 57.00%\n",
      "Step:     0\tLoss: 9.111\tAcc: 63.00%\n",
      "Step:     0\tLoss: 11.426\tAcc: 64.00%\n",
      "Step:     0\tLoss: 6.415\tAcc: 78.00%\n",
      "Step:     0\tLoss: 6.844\tAcc: 68.00%\n",
      "Step:     0\tLoss: 6.363\tAcc: 70.00%\n",
      "Step:     0\tLoss: 4.803\tAcc: 73.00%\n",
      "Step:     0\tLoss: 6.262\tAcc: 74.00%\n",
      "Step:     0\tLoss: 4.126\tAcc: 80.00%\n",
      "Step:     0\tLoss: 3.883\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.700\tAcc: 75.00%\n",
      "Step:     0\tLoss: 4.795\tAcc: 76.00%\n",
      "Step:     0\tLoss: 5.145\tAcc: 78.00%\n",
      "Step:     0\tLoss: 5.094\tAcc: 76.00%\n",
      "Step:     0\tLoss: 3.131\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.419\tAcc: 84.00%\n",
      "Step:     0\tLoss: 7.157\tAcc: 67.00%\n",
      "Step:     0\tLoss: 12.713\tAcc: 56.00%\n",
      "Step:     0\tLoss: 12.441\tAcc: 69.00%\n",
      "Step:     0\tLoss: 5.670\tAcc: 78.00%\n",
      "Step:     0\tLoss: 4.034\tAcc: 77.00%\n",
      "Step:     0\tLoss: 1.782\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.922\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.873\tAcc: 85.00%\n",
      "Step:     0\tLoss: 4.945\tAcc: 78.00%\n",
      "Step:     0\tLoss: 1.557\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.218\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.239\tAcc: 84.00%\n",
      "Step:     0\tLoss: 3.519\tAcc: 80.00%\n",
      "Step:     0\tLoss: 3.291\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.396\tAcc: 86.00%\n",
      "Step:     0\tLoss: 3.065\tAcc: 84.00%\n",
      "Step:     0\tLoss: 4.033\tAcc: 77.00%\n",
      "Step:     0\tLoss: 2.591\tAcc: 77.00%\n",
      "Step:     0\tLoss: 1.199\tAcc: 89.00%\n",
      "Step:     0\tLoss: 3.172\tAcc: 77.00%\n",
      "Step:     0\tLoss: 2.088\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.633\tAcc: 79.00%\n",
      "Step:     0\tLoss: 3.735\tAcc: 77.00%\n",
      "Step:     0\tLoss: 2.361\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.359\tAcc: 86.00%\n",
      "Step:     0\tLoss: 4.426\tAcc: 79.00%\n",
      "Step:     0\tLoss: 7.555\tAcc: 66.00%\n",
      "Step:     0\tLoss: 12.564\tAcc: 77.00%\n",
      "Step:     0\tLoss: 4.555\tAcc: 79.00%\n",
      "Step:     0\tLoss: 3.530\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.590\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.717\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.296\tAcc: 86.00%\n",
      "Step:     0\tLoss: 4.451\tAcc: 77.00%\n",
      "Step:     0\tLoss: 3.601\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.985\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.307\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.590\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.512\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.497\tAcc: 85.00%\n",
      "Step:     0\tLoss: 4.612\tAcc: 83.00%\n",
      "Step:     0\tLoss: 5.529\tAcc: 67.00%\n",
      "Step:     0\tLoss: 4.177\tAcc: 81.00%\n",
      "Step:     0\tLoss: 4.324\tAcc: 78.00%\n",
      "Step:     0\tLoss: 3.777\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.939\tAcc: 80.00%\n",
      "Step:     0\tLoss: 3.069\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.001\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.282\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.496\tAcc: 84.00%\n",
      "Step:     0\tLoss: 4.096\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.412\tAcc: 82.00%\n",
      "Step:     0\tLoss: 3.071\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.210\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.496\tAcc: 89.00%\n",
      "Step:     0\tLoss: 0.790\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.689\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.782\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.434\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.430\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.281\tAcc: 80.00%\n",
      "Step:     0\tLoss: 4.314\tAcc: 77.00%\n",
      "Step:     0\tLoss: 7.147\tAcc: 67.00%\n",
      "Step:     0\tLoss: 6.052\tAcc: 72.00%\n",
      "Step:     0\tLoss: 7.439\tAcc: 69.00%\n",
      "Step:     0\tLoss: 7.275\tAcc: 75.00%\n",
      "Step:     0\tLoss: 4.621\tAcc: 82.00%\n",
      "Step:     0\tLoss: 3.612\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.930\tAcc: 80.00%\n",
      "Step:     0\tLoss: 5.850\tAcc: 73.00%\n",
      "Step:     0\tLoss: 3.305\tAcc: 77.00%\n",
      "Step:     0\tLoss: 1.943\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.540\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.048\tAcc: 93.00%\n",
      "Step:     0\tLoss: 1.587\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.349\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.950\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.755\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.040\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.133\tAcc: 84.00%\n",
      "Step:     0\tLoss: 3.553\tAcc: 78.00%\n",
      "Step:     0\tLoss: 3.712\tAcc: 79.00%\n",
      "Step:     0\tLoss: 1.747\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.750\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.377\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.526\tAcc: 87.00%\n",
      "Step:     0\tLoss: 3.415\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.165\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.312\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.434\tAcc: 80.00%\n",
      "Step:     0\tLoss: 6.930\tAcc: 66.00%\n",
      "Step:     0\tLoss: 11.925\tAcc: 80.00%\n",
      "Step:     0\tLoss: 4.405\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.070\tAcc: 82.00%\n",
      "Step:     0\tLoss: 1.900\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.885\tAcc: 82.00%\n",
      "Step:     0\tLoss: 3.453\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.355\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.087\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.349\tAcc: 82.00%\n",
      "Step:     0\tLoss: 3.484\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.322\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.007\tAcc: 93.00%\n",
      "Step:     0\tLoss: 2.362\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.087\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.138\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.585\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.596\tAcc: 84.00%\n",
      "Step:     0\tLoss: 4.373\tAcc: 86.00%\n",
      "Step:     0\tLoss: 0.598\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.743\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.022\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.832\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.372\tAcc: 87.00%\n",
      "Step:     0\tLoss: 3.650\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.982\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.151\tAcc: 91.00%\n",
      "Step:     0\tLoss: 3.264\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.114\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.563\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.097\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.063\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.655\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.131\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.868\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.385\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.776\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.534\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.360\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.881\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.672\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.842\tAcc: 80.00%\n",
      "Step:     0\tLoss: 3.766\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.356\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.085\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.275\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.906\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.627\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.040\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.028\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.417\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.203\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.114\tAcc: 74.00%\n",
      "Step:     0\tLoss: 7.449\tAcc: 74.00%\n",
      "Step:     0\tLoss: 2.890\tAcc: 75.00%\n",
      "Step:     0\tLoss: 5.923\tAcc: 78.00%\n",
      "Step:     0\tLoss: 6.512\tAcc: 70.00%\n",
      "Step:     0\tLoss: 2.843\tAcc: 81.00%\n",
      "Step:     0\tLoss: 3.194\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.223\tAcc: 83.00%\n",
      "Step:     0\tLoss: 3.847\tAcc: 82.00%\n",
      "Step:     0\tLoss: 7.501\tAcc: 70.00%\n",
      "Step:     0\tLoss: 11.702\tAcc: 65.00%\n",
      "Step:     0\tLoss: 2.931\tAcc: 81.00%\n",
      "Step:     0\tLoss: 3.141\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.705\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.600\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.367\tAcc: 90.00%\n",
      "Step:     0\tLoss: 3.043\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.168\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.632\tAcc: 83.00%\n",
      "Step:     0\tLoss: 0.923\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.320\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.628\tAcc: 86.00%\n",
      "Step:     0\tLoss: 5.162\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.097\tAcc: 82.00%\n",
      "Step:     0\tLoss: 4.325\tAcc: 80.00%\n",
      "Step:     0\tLoss: 4.064\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.016\tAcc: 88.00%\n",
      "Step:     0\tLoss: 4.372\tAcc: 76.00%\n",
      "Step:     0\tLoss: 6.093\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.962\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.005\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.696\tAcc: 82.00%\n",
      "Step:     0\tLoss: 7.089\tAcc: 67.00%\n",
      "Step:     0\tLoss: 4.329\tAcc: 75.00%\n",
      "Step:     0\tLoss: 3.487\tAcc: 81.00%\n",
      "Step:     0\tLoss: 6.113\tAcc: 71.00%\n",
      "Step:     0\tLoss: 6.109\tAcc: 70.00%\n",
      "Step:     0\tLoss: 4.798\tAcc: 71.00%\n",
      "Step:     0\tLoss: 7.841\tAcc: 77.00%\n",
      "Step:     0\tLoss: 1.600\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.173\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.883\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.157\tAcc: 84.00%\n",
      "Step:     0\tLoss: 3.349\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.200\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.114\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.787\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.297\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.674\tAcc: 84.00%\n",
      "Step:     0\tLoss: 0.373\tAcc: 95.00%\n",
      "Step:     0\tLoss: 1.249\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.399\tAcc: 89.00%\n",
      "Step:     0\tLoss: 3.851\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.900\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.116\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.537\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.375\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.001\tAcc: 83.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 1.350\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.317\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.809\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.183\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.410\tAcc: 86.00%\n",
      "Step:     0\tLoss: 4.184\tAcc: 74.00%\n",
      "Step:     0\tLoss: 5.075\tAcc: 70.00%\n",
      "Step:     0\tLoss: 5.068\tAcc: 74.00%\n",
      "Step:     0\tLoss: 3.136\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.612\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.102\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.015\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.743\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.171\tAcc: 92.00%\n",
      "Step:     0\tLoss: 2.604\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.564\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.774\tAcc: 84.00%\n",
      "Step:     0\tLoss: 3.210\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.480\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.827\tAcc: 86.00%\n",
      "Step:     0\tLoss: 3.061\tAcc: 83.00%\n",
      "Step:     0\tLoss: 3.633\tAcc: 74.00%\n",
      "Step:     0\tLoss: 6.239\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.435\tAcc: 88.00%\n",
      "Step:     0\tLoss: 3.730\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.416\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.049\tAcc: 85.00%\n",
      "Step:     0\tLoss: 4.337\tAcc: 81.00%\n",
      "Step:     0\tLoss: 5.736\tAcc: 77.00%\n",
      "Step:     0\tLoss: 4.719\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.738\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.116\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.571\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.028\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.702\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.366\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.963\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.044\tAcc: 94.00%\n",
      "Step:     0\tLoss: 2.744\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.530\tAcc: 89.00%\n",
      "Step:     0\tLoss: 0.969\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.572\tAcc: 92.00%\n",
      "Step:     0\tLoss: 2.702\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.035\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.795\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.256\tAcc: 86.00%\n",
      "Step:     0\tLoss: 0.600\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.060\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.355\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.190\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.280\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.946\tAcc: 84.00%\n",
      "Step:     0\tLoss: 3.637\tAcc: 78.00%\n",
      "Step:     0\tLoss: 5.888\tAcc: 78.00%\n",
      "Step:     0\tLoss: 1.528\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.977\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.552\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.430\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.641\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.744\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.675\tAcc: 87.00%\n",
      "Step:     0\tLoss: 4.437\tAcc: 75.00%\n",
      "Step:     0\tLoss: 4.570\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.724\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.566\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.434\tAcc: 87.00%\n",
      "Step:     0\tLoss: 3.062\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.318\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.801\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.720\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.406\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.477\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.174\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.833\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.951\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.053\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.233\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.876\tAcc: 83.00%\n",
      "Step:     0\tLoss: 8.055\tAcc: 74.00%\n",
      "Step:     0\tLoss: 14.048\tAcc: 54.00%\n",
      "Step:     0\tLoss: 21.232\tAcc: 70.00%\n",
      "Step:     0\tLoss: 10.513\tAcc: 66.00%\n",
      "Step:     0\tLoss: 4.130\tAcc: 75.00%\n",
      "Step:     0\tLoss: 2.352\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.623\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.944\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.251\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.228\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.042\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.756\tAcc: 82.00%\n",
      "Step:     0\tLoss: 1.098\tAcc: 92.00%\n",
      "Step:     0\tLoss: 2.709\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.631\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.913\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.873\tAcc: 87.00%\n",
      "Step:     0\tLoss: 6.509\tAcc: 77.00%\n",
      "Step:     0\tLoss: 5.457\tAcc: 76.00%\n",
      "Step:     0\tLoss: 4.661\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.117\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.496\tAcc: 89.00%\n",
      "Step:     0\tLoss: 3.588\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.712\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.766\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.977\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.523\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.693\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.543\tAcc: 83.00%\n",
      "Step:     0\tLoss: 3.363\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.767\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.798\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.082\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.659\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.957\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.161\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.002\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.350\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.619\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.005\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.536\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.997\tAcc: 87.00%\n",
      "Step:     0\tLoss: 3.992\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.424\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.281\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.814\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.953\tAcc: 82.00%\n",
      "Step:     0\tLoss: 1.979\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.118\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.990\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.284\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.391\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.472\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.924\tAcc: 81.00%\n",
      "Step:     0\tLoss: 3.194\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.003\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.637\tAcc: 94.00%\n",
      "Step:     0\tLoss: 2.272\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.389\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.631\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.628\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.710\tAcc: 87.00%\n",
      "Step:     0\tLoss: 3.506\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.982\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.672\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.119\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.168\tAcc: 90.00%\n",
      "Step:     0\tLoss: 0.814\tAcc: 93.00%\n",
      "Step:     0\tLoss: 1.299\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.836\tAcc: 82.00%\n",
      "Step:     0\tLoss: 2.486\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.457\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.251\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.915\tAcc: 89.00%\n",
      "Step:     0\tLoss: 0.999\tAcc: 89.00%\n",
      "Step:     0\tLoss: 3.191\tAcc: 80.00%\n",
      "Step:     0\tLoss: 1.998\tAcc: 85.00%\n",
      "Step:     0\tLoss: 4.463\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.163\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.720\tAcc: 78.00%\n",
      "Step:     0\tLoss: 4.709\tAcc: 78.00%\n",
      "Step:     0\tLoss: 1.782\tAcc: 86.00%\n",
      "Step:     0\tLoss: 3.906\tAcc: 81.00%\n",
      "Step:     0\tLoss: 4.266\tAcc: 76.00%\n",
      "Step:     0\tLoss: 3.398\tAcc: 78.00%\n",
      "Step:     0\tLoss: 4.236\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.253\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.685\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.371\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.130\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.652\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.829\tAcc: 86.00%\n",
      "Step:     0\tLoss: 0.928\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.708\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.403\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.996\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.197\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.118\tAcc: 89.00%\n",
      "Step:     0\tLoss: 0.386\tAcc: 95.00%\n",
      "Step:     0\tLoss: 1.137\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.056\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.345\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.335\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.903\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.999\tAcc: 85.00%\n",
      "Step:     0\tLoss: 0.615\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.335\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.321\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.202\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.934\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.490\tAcc: 82.00%\n",
      "Step:     0\tLoss: 1.655\tAcc: 93.00%\n",
      "Step:     0\tLoss: 1.365\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.856\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.338\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.009\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.638\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.836\tAcc: 91.00%\n",
      "Step:     0\tLoss: 0.976\tAcc: 93.00%\n",
      "Step:     0\tLoss: 0.397\tAcc: 93.00%\n",
      "Step:     0\tLoss: 0.287\tAcc: 94.00%\n",
      "Step:     0\tLoss: 1.042\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.635\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.365\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.656\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.941\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.208\tAcc: 88.00%\n",
      "Step:     0\tLoss: 0.661\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.015\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.862\tAcc: 81.00%\n",
      "Step:     0\tLoss: 3.796\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.493\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.172\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.811\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.266\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.697\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.602\tAcc: 92.00%\n",
      "Step:     0\tLoss: 1.699\tAcc: 92.00%\n",
      "Step:     0\tLoss: 3.746\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.051\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.716\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.738\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.051\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.436\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.949\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.341\tAcc: 84.00%\n",
      "Step:     0\tLoss: 6.845\tAcc: 73.00%\n",
      "Step:     0\tLoss: 3.088\tAcc: 81.00%\n",
      "Step:     0\tLoss: 3.617\tAcc: 81.00%\n",
      "Step:     0\tLoss: 1.361\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.927\tAcc: 93.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0\tLoss: 1.358\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.141\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.727\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.045\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.085\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.376\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.159\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.285\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.861\tAcc: 90.00%\n",
      "Step:     0\tLoss: 1.149\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.552\tAcc: 91.00%\n",
      "Step:     0\tLoss: 2.168\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.474\tAcc: 77.00%\n",
      "Step:     0\tLoss: 3.819\tAcc: 78.00%\n",
      "Step:     0\tLoss: 2.003\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.683\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.157\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.691\tAcc: 85.00%\n",
      "Step:     0\tLoss: 1.904\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.070\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.973\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.562\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.097\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.428\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.770\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.880\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.869\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.095\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.505\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.130\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.129\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.740\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.953\tAcc: 87.00%\n",
      "Step:     0\tLoss: 0.936\tAcc: 97.00%\n",
      "Step:     0\tLoss: 1.781\tAcc: 86.00%\n",
      "Step:     0\tLoss: 2.189\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.184\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.895\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.310\tAcc: 86.00%\n",
      "Step:     0\tLoss: 3.222\tAcc: 84.00%\n",
      "Step:     0\tLoss: 5.445\tAcc: 78.00%\n",
      "Step:     0\tLoss: 4.628\tAcc: 83.00%\n",
      "Step:     0\tLoss: 1.095\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.545\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.192\tAcc: 92.00%\n",
      "Step:     0\tLoss: 0.905\tAcc: 93.00%\n",
      "Step:     0\tLoss: 1.373\tAcc: 90.00%\n",
      "Step:     0\tLoss: 2.337\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.862\tAcc: 86.00%\n",
      "Step:     0\tLoss: 3.719\tAcc: 83.00%\n",
      "Step:     0\tLoss: 2.092\tAcc: 84.00%\n",
      "Step:     0\tLoss: 1.680\tAcc: 91.00%\n",
      "Step:     0\tLoss: 1.486\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.448\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.198\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.231\tAcc: 88.00%\n",
      "Step:     0\tLoss: 1.249\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.586\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.072\tAcc: 95.00%\n",
      "Step:     0\tLoss: 1.521\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.010\tAcc: 93.00%\n",
      "Step:     0\tLoss: 2.032\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.163\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.549\tAcc: 83.00%\n",
      "Step:     0\tLoss: 4.258\tAcc: 79.00%\n",
      "Step:     0\tLoss: 7.556\tAcc: 68.00%\n",
      "Step:     0\tLoss: 7.771\tAcc: 77.00%\n",
      "Step:     0\tLoss: 2.344\tAcc: 83.00%\n",
      "Step:     0\tLoss: 3.297\tAcc: 78.00%\n",
      "Step:     0\tLoss: 3.643\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.800\tAcc: 81.00%\n",
      "Step:     0\tLoss: 6.183\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.796\tAcc: 79.00%\n",
      "Step:     0\tLoss: 2.873\tAcc: 82.00%\n",
      "Step:     0\tLoss: 1.020\tAcc: 89.00%\n",
      "Step:     0\tLoss: 1.481\tAcc: 89.00%\n",
      "Step:     0\tLoss: 2.855\tAcc: 83.00%\n",
      "Step:     0\tLoss: 4.474\tAcc: 80.00%\n",
      "Step:     0\tLoss: 2.800\tAcc: 86.00%\n",
      "Step:     0\tLoss: 1.382\tAcc: 93.00%\n",
      "Step:     0\tLoss: 2.010\tAcc: 87.00%\n",
      "Step:     0\tLoss: 1.625\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.849\tAcc: 85.00%\n",
      "Step:     0\tLoss: 3.582\tAcc: 84.00%\n",
      "Step:     0\tLoss: 2.009\tAcc: 87.00%\n",
      "Step:     0\tLoss: 2.235\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.160\tAcc: 88.00%\n",
      "Step:     0\tLoss: 2.274\tAcc: 82.00%\n",
      "Step:     0\tLoss: 3.734\tAcc: 79.00%\n",
      "Step:     0\tLoss: 4.247\tAcc: 81.00%\n",
      "Step:     0\tLoss: 4.537\tAcc: 81.00%\n",
      "Step:     0\tLoss: 2.204\tAcc: 85.00%\n",
      "Step:     0\tLoss: 2.032\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.373\tAcc: 85.00%\n",
      "Step:     1\tLoss: 0.920\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.683\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.898\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.970\tAcc: 87.00%\n",
      "Step:     1\tLoss: 4.218\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.899\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.237\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.840\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.788\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.691\tAcc: 86.00%\n",
      "Step:     1\tLoss: 4.269\tAcc: 82.00%\n",
      "Step:     1\tLoss: 1.934\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.069\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.287\tAcc: 94.00%\n",
      "Step:     1\tLoss: 2.282\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.974\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.722\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.864\tAcc: 91.00%\n",
      "Step:     1\tLoss: 2.697\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.308\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.864\tAcc: 92.00%\n",
      "Step:     1\tLoss: 2.209\tAcc: 81.00%\n",
      "Step:     1\tLoss: 2.836\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.179\tAcc: 82.00%\n",
      "Step:     1\tLoss: 4.487\tAcc: 80.00%\n",
      "Step:     1\tLoss: 2.155\tAcc: 82.00%\n",
      "Step:     1\tLoss: 2.535\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.341\tAcc: 91.00%\n",
      "Step:     1\tLoss: 2.217\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.738\tAcc: 87.00%\n",
      "Step:     1\tLoss: 3.161\tAcc: 82.00%\n",
      "Step:     1\tLoss: 2.090\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.596\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.509\tAcc: 95.00%\n",
      "Step:     1\tLoss: 1.488\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.657\tAcc: 91.00%\n",
      "Step:     1\tLoss: 3.071\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.737\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.414\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.877\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.948\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.475\tAcc: 80.00%\n",
      "Step:     1\tLoss: 2.963\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.947\tAcc: 82.00%\n",
      "Step:     1\tLoss: 1.133\tAcc: 92.00%\n",
      "Step:     1\tLoss: 2.714\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.870\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.600\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.840\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.515\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.042\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.160\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.122\tAcc: 92.00%\n",
      "Step:     1\tLoss: 3.217\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.688\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.974\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.490\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.076\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.430\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.745\tAcc: 82.00%\n",
      "Step:     1\tLoss: 0.853\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.800\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.837\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.450\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.126\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.998\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.088\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.878\tAcc: 90.00%\n",
      "Step:     1\tLoss: 3.796\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.040\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.628\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.427\tAcc: 96.00%\n",
      "Step:     1\tLoss: 0.581\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.914\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.443\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.896\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.799\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.771\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.665\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.006\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.186\tAcc: 87.00%\n",
      "Step:     1\tLoss: 4.681\tAcc: 78.00%\n",
      "Step:     1\tLoss: 2.416\tAcc: 78.00%\n",
      "Step:     1\tLoss: 3.554\tAcc: 77.00%\n",
      "Step:     1\tLoss: 2.532\tAcc: 79.00%\n",
      "Step:     1\tLoss: 2.749\tAcc: 80.00%\n",
      "Step:     1\tLoss: 6.833\tAcc: 72.00%\n",
      "Step:     1\tLoss: 10.175\tAcc: 79.00%\n",
      "Step:     1\tLoss: 1.764\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.769\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.522\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.324\tAcc: 97.00%\n",
      "Step:     1\tLoss: 1.160\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.560\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.267\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.575\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.684\tAcc: 94.00%\n",
      "Step:     1\tLoss: 2.494\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.808\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.664\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.924\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.824\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.683\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.799\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.918\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.857\tAcc: 78.00%\n",
      "Step:     1\tLoss: 6.650\tAcc: 64.00%\n",
      "Step:     1\tLoss: 7.698\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.515\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.985\tAcc: 85.00%\n",
      "Step:     1\tLoss: 5.097\tAcc: 77.00%\n",
      "Step:     1\tLoss: 4.390\tAcc: 78.00%\n",
      "Step:     1\tLoss: 4.496\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.421\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.955\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.484\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.630\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.566\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.573\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.678\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.890\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.759\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.944\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.568\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.614\tAcc: 94.00%\n",
      "Step:     1\tLoss: 0.868\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.135\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.721\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.996\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.677\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.721\tAcc: 81.00%\n",
      "Step:     1\tLoss: 3.435\tAcc: 77.00%\n",
      "Step:     1\tLoss: 3.337\tAcc: 79.00%\n",
      "Step:     1\tLoss: 1.841\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.157\tAcc: 84.00%\n",
      "Step:     1\tLoss: 0.726\tAcc: 94.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     1\tLoss: 2.902\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.846\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.124\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.993\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.868\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.232\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.646\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.943\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.783\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.066\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.524\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.394\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.076\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.524\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.506\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.386\tAcc: 94.00%\n",
      "Step:     1\tLoss: 0.709\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.580\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.905\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.967\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.546\tAcc: 82.00%\n",
      "Step:     1\tLoss: 1.957\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.353\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.597\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.939\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.796\tAcc: 87.00%\n",
      "Step:     1\tLoss: 3.004\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.112\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.217\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.950\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.356\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.765\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.457\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.678\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.024\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.505\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.718\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.260\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.482\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.592\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.080\tAcc: 95.00%\n",
      "Step:     1\tLoss: 1.415\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.962\tAcc: 88.00%\n",
      "Step:     1\tLoss: 4.746\tAcc: 76.00%\n",
      "Step:     1\tLoss: 1.407\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.891\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.596\tAcc: 86.00%\n",
      "Step:     1\tLoss: 3.401\tAcc: 83.00%\n",
      "Step:     1\tLoss: 4.656\tAcc: 81.00%\n",
      "Step:     1\tLoss: 3.554\tAcc: 81.00%\n",
      "Step:     1\tLoss: 5.250\tAcc: 78.00%\n",
      "Step:     1\tLoss: 5.035\tAcc: 81.00%\n",
      "Step:     1\tLoss: 0.361\tAcc: 94.00%\n",
      "Step:     1\tLoss: 2.228\tAcc: 87.00%\n",
      "Step:     1\tLoss: 4.258\tAcc: 79.00%\n",
      "Step:     1\tLoss: 2.734\tAcc: 82.00%\n",
      "Step:     1\tLoss: 0.962\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.350\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.084\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.399\tAcc: 95.00%\n",
      "Step:     1\tLoss: 0.878\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.638\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.723\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.208\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.334\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.162\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.174\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.328\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.662\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.352\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.082\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.353\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.054\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.252\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.792\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.933\tAcc: 85.00%\n",
      "Step:     1\tLoss: 3.689\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.707\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.388\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.699\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.223\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.443\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.502\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.300\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.886\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.758\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.631\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.500\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.270\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.971\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.558\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.694\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.352\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.455\tAcc: 87.00%\n",
      "Step:     1\tLoss: 3.773\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.038\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.508\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.399\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.169\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.984\tAcc: 81.00%\n",
      "Step:     1\tLoss: 3.617\tAcc: 78.00%\n",
      "Step:     1\tLoss: 1.647\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.469\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.815\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.648\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.394\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.691\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.913\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.543\tAcc: 94.00%\n",
      "Step:     1\tLoss: 2.028\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.731\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.575\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.059\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.279\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.525\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.701\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.053\tAcc: 83.00%\n",
      "Step:     1\tLoss: 5.373\tAcc: 66.00%\n",
      "Step:     1\tLoss: 11.231\tAcc: 77.00%\n",
      "Step:     1\tLoss: 8.994\tAcc: 68.00%\n",
      "Step:     1\tLoss: 9.682\tAcc: 67.00%\n",
      "Step:     1\tLoss: 10.277\tAcc: 83.00%\n",
      "Step:     1\tLoss: 3.356\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.303\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.174\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.451\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.882\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.458\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.321\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.442\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.908\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.249\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.936\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.661\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.488\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.250\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.081\tAcc: 95.00%\n",
      "Step:     1\tLoss: 2.405\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.889\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.605\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.143\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.856\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.615\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.730\tAcc: 82.00%\n",
      "Step:     1\tLoss: 6.283\tAcc: 73.00%\n",
      "Step:     1\tLoss: 3.157\tAcc: 84.00%\n",
      "Step:     1\tLoss: 3.205\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.217\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.858\tAcc: 90.00%\n",
      "Step:     1\tLoss: 3.231\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.171\tAcc: 90.00%\n",
      "Step:     1\tLoss: 3.051\tAcc: 88.00%\n",
      "Step:     1\tLoss: 3.017\tAcc: 83.00%\n",
      "Step:     1\tLoss: 4.004\tAcc: 79.00%\n",
      "Step:     1\tLoss: 6.690\tAcc: 75.00%\n",
      "Step:     1\tLoss: 3.588\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.417\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.486\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.887\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.114\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.400\tAcc: 86.00%\n",
      "Step:     1\tLoss: 0.746\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.290\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.500\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.304\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.431\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.847\tAcc: 93.00%\n",
      "Step:     1\tLoss: 0.801\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.929\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.402\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.335\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.112\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.560\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.178\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.402\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.729\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.144\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.737\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.639\tAcc: 95.00%\n",
      "Step:     1\tLoss: 1.498\tAcc: 87.00%\n",
      "Step:     1\tLoss: 3.523\tAcc: 79.00%\n",
      "Step:     1\tLoss: 2.788\tAcc: 81.00%\n",
      "Step:     1\tLoss: 2.415\tAcc: 80.00%\n",
      "Step:     1\tLoss: 1.007\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.832\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.368\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.145\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.647\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.625\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.231\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.049\tAcc: 92.00%\n",
      "Step:     1\tLoss: 4.769\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.338\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.681\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.298\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.759\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.124\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.692\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.550\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.676\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.233\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.362\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.897\tAcc: 87.00%\n",
      "Step:     1\tLoss: 4.299\tAcc: 75.00%\n",
      "Step:     1\tLoss: 8.714\tAcc: 69.00%\n",
      "Step:     1\tLoss: 7.734\tAcc: 80.00%\n",
      "Step:     1\tLoss: 3.493\tAcc: 84.00%\n",
      "Step:     1\tLoss: 3.513\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.589\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.962\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.263\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.802\tAcc: 85.00%\n",
      "Step:     1\tLoss: 0.737\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.896\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.391\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.516\tAcc: 86.00%\n",
      "Step:     1\tLoss: 0.578\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.928\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.465\tAcc: 78.00%\n",
      "Step:     1\tLoss: 1.787\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.770\tAcc: 82.00%\n",
      "Step:     1\tLoss: 3.305\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.959\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.859\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.023\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.025\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.767\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.472\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.749\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.478\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.685\tAcc: 93.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     1\tLoss: 1.360\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.767\tAcc: 82.00%\n",
      "Step:     1\tLoss: 2.747\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.257\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.621\tAcc: 88.00%\n",
      "Step:     1\tLoss: 3.576\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.769\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.646\tAcc: 81.00%\n",
      "Step:     1\tLoss: 3.312\tAcc: 76.00%\n",
      "Step:     1\tLoss: 8.342\tAcc: 77.00%\n",
      "Step:     1\tLoss: 3.006\tAcc: 82.00%\n",
      "Step:     1\tLoss: 3.848\tAcc: 84.00%\n",
      "Step:     1\tLoss: 3.185\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.460\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.172\tAcc: 85.00%\n",
      "Step:     1\tLoss: 0.836\tAcc: 91.00%\n",
      "Step:     1\tLoss: 2.486\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.328\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.735\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.690\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.503\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.527\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.907\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.079\tAcc: 91.00%\n",
      "Step:     1\tLoss: 3.563\tAcc: 82.00%\n",
      "Step:     1\tLoss: 3.402\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.398\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.468\tAcc: 82.00%\n",
      "Step:     1\tLoss: 1.103\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.772\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.318\tAcc: 95.00%\n",
      "Step:     1\tLoss: 0.705\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.202\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.712\tAcc: 90.00%\n",
      "Step:     1\tLoss: 0.987\tAcc: 94.00%\n",
      "Step:     1\tLoss: 2.536\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.753\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.451\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.211\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.839\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.469\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.994\tAcc: 84.00%\n",
      "Step:     1\tLoss: 3.517\tAcc: 74.00%\n",
      "Step:     1\tLoss: 2.118\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.529\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.604\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.190\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.267\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.924\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.265\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.788\tAcc: 85.00%\n",
      "Step:     1\tLoss: 0.890\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.571\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.748\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.039\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.114\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.944\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.978\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.697\tAcc: 85.00%\n",
      "Step:     1\tLoss: 3.025\tAcc: 80.00%\n",
      "Step:     1\tLoss: 2.609\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.392\tAcc: 88.00%\n",
      "Step:     1\tLoss: 3.253\tAcc: 85.00%\n",
      "Step:     1\tLoss: 3.680\tAcc: 83.00%\n",
      "Step:     1\tLoss: 4.055\tAcc: 82.00%\n",
      "Step:     1\tLoss: 2.298\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.738\tAcc: 87.00%\n",
      "Step:     1\tLoss: 3.402\tAcc: 79.00%\n",
      "Step:     1\tLoss: 1.885\tAcc: 82.00%\n",
      "Step:     1\tLoss: 1.924\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.557\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.118\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.069\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.809\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.505\tAcc: 81.00%\n",
      "Step:     1\tLoss: 1.337\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.622\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.930\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.130\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.807\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.543\tAcc: 94.00%\n",
      "Step:     1\tLoss: 3.258\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.025\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.889\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.302\tAcc: 79.00%\n",
      "Step:     1\tLoss: 2.181\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.570\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.939\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.115\tAcc: 83.00%\n",
      "Step:     1\tLoss: 3.335\tAcc: 75.00%\n",
      "Step:     1\tLoss: 5.587\tAcc: 74.00%\n",
      "Step:     1\tLoss: 2.540\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.269\tAcc: 89.00%\n",
      "Step:     1\tLoss: 3.059\tAcc: 89.00%\n",
      "Step:     1\tLoss: 2.138\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.078\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.774\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.406\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.260\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.330\tAcc: 94.00%\n",
      "Step:     1\tLoss: 0.686\tAcc: 96.00%\n",
      "Step:     1\tLoss: 2.360\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.098\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.499\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.172\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.438\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.432\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.319\tAcc: 91.00%\n",
      "Step:     1\tLoss: 2.094\tAcc: 81.00%\n",
      "Step:     1\tLoss: 2.124\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.711\tAcc: 87.00%\n",
      "Step:     1\tLoss: 2.743\tAcc: 81.00%\n",
      "Step:     1\tLoss: 3.470\tAcc: 76.00%\n",
      "Step:     1\tLoss: 6.199\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.770\tAcc: 83.00%\n",
      "Step:     1\tLoss: 1.627\tAcc: 88.00%\n",
      "Step:     1\tLoss: 0.693\tAcc: 94.00%\n",
      "Step:     1\tLoss: 0.220\tAcc: 97.00%\n",
      "Step:     1\tLoss: 1.952\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.156\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.810\tAcc: 93.00%\n",
      "Step:     1\tLoss: 2.146\tAcc: 89.00%\n",
      "Step:     1\tLoss: 0.723\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.927\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.497\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.430\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.692\tAcc: 94.00%\n",
      "Step:     1\tLoss: 1.341\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.123\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.668\tAcc: 86.00%\n",
      "Step:     1\tLoss: 0.980\tAcc: 91.00%\n",
      "Step:     1\tLoss: 0.641\tAcc: 94.00%\n",
      "Step:     1\tLoss: 0.634\tAcc: 93.00%\n",
      "Step:     1\tLoss: 1.781\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.198\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.624\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.546\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.961\tAcc: 85.00%\n",
      "Step:     1\tLoss: 3.975\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.385\tAcc: 87.00%\n",
      "Step:     1\tLoss: 4.197\tAcc: 82.00%\n",
      "Step:     1\tLoss: 3.169\tAcc: 84.00%\n",
      "Step:     1\tLoss: 4.310\tAcc: 76.00%\n",
      "Step:     1\tLoss: 3.554\tAcc: 79.00%\n",
      "Step:     1\tLoss: 1.723\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.466\tAcc: 91.00%\n",
      "Step:     1\tLoss: 2.251\tAcc: 91.00%\n",
      "Step:     1\tLoss: 1.408\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.488\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.762\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.728\tAcc: 88.00%\n",
      "Step:     1\tLoss: 2.451\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.647\tAcc: 86.00%\n",
      "Step:     1\tLoss: 2.168\tAcc: 85.00%\n",
      "Step:     1\tLoss: 2.825\tAcc: 84.00%\n",
      "Step:     1\tLoss: 2.529\tAcc: 87.00%\n",
      "Step:     1\tLoss: 1.572\tAcc: 92.00%\n",
      "Step:     1\tLoss: 2.245\tAcc: 85.00%\n",
      "Step:     1\tLoss: 1.551\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.466\tAcc: 84.00%\n",
      "Step:     1\tLoss: 0.566\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.751\tAcc: 90.00%\n",
      "Step:     1\tLoss: 1.127\tAcc: 92.00%\n",
      "Step:     1\tLoss: 0.754\tAcc: 88.00%\n",
      "Step:     1\tLoss: 1.185\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.978\tAcc: 82.00%\n",
      "Step:     1\tLoss: 3.071\tAcc: 82.00%\n",
      "Step:     1\tLoss: 2.109\tAcc: 90.00%\n",
      "Step:     1\tLoss: 2.130\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.891\tAcc: 87.00%\n",
      "Step:     1\tLoss: 0.835\tAcc: 92.00%\n",
      "Step:     1\tLoss: 1.720\tAcc: 89.00%\n",
      "Step:     1\tLoss: 1.582\tAcc: 84.00%\n",
      "Step:     1\tLoss: 1.462\tAcc: 86.00%\n",
      "Step:     1\tLoss: 1.653\tAcc: 83.00%\n",
      "Step:     1\tLoss: 4.351\tAcc: 75.00%\n",
      "Step:     1\tLoss: 3.232\tAcc: 79.00%\n",
      "Step:     1\tLoss: 2.986\tAcc: 80.00%\n",
      "Step:     1\tLoss: 1.729\tAcc: 85.00%\n",
      "Step:     1\tLoss: 3.460\tAcc: 83.00%\n",
      "Step:     1\tLoss: 2.098\tAcc: 86.00%\n",
      "Step:     1\tLoss: 3.787\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.214\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.961\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.459\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.420\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.982\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.103\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.896\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.715\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.970\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.568\tAcc: 96.00%\n",
      "Step:     2\tLoss: 1.637\tAcc: 95.00%\n",
      "Step:     2\tLoss: 2.326\tAcc: 80.00%\n",
      "Step:     2\tLoss: 1.965\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.296\tAcc: 85.00%\n",
      "Step:     2\tLoss: 3.898\tAcc: 78.00%\n",
      "Step:     2\tLoss: 8.902\tAcc: 74.00%\n",
      "Step:     2\tLoss: 8.256\tAcc: 73.00%\n",
      "Step:     2\tLoss: 0.937\tAcc: 92.00%\n",
      "Step:     2\tLoss: 3.422\tAcc: 79.00%\n",
      "Step:     2\tLoss: 3.779\tAcc: 79.00%\n",
      "Step:     2\tLoss: 3.376\tAcc: 78.00%\n",
      "Step:     2\tLoss: 2.506\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.152\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.183\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.973\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.268\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.799\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.092\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.803\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.624\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.531\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.713\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.597\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.855\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.145\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.933\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.999\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.921\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.436\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.203\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.154\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.968\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.031\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.048\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.069\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.116\tAcc: 96.00%\n",
      "Step:     2\tLoss: 2.330\tAcc: 86.00%\n",
      "Step:     2\tLoss: 5.468\tAcc: 79.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     2\tLoss: 3.707\tAcc: 80.00%\n",
      "Step:     2\tLoss: 4.345\tAcc: 83.00%\n",
      "Step:     2\tLoss: 3.059\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.159\tAcc: 86.00%\n",
      "Step:     2\tLoss: 0.583\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.785\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.329\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.404\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.409\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.896\tAcc: 84.00%\n",
      "Step:     2\tLoss: 0.834\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.595\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.586\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.986\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.039\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.446\tAcc: 87.00%\n",
      "Step:     2\tLoss: 0.434\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.238\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.135\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.261\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.667\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.986\tAcc: 83.00%\n",
      "Step:     2\tLoss: 4.678\tAcc: 74.00%\n",
      "Step:     2\tLoss: 3.353\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.237\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.542\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.937\tAcc: 82.00%\n",
      "Step:     2\tLoss: 1.638\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.700\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.817\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.253\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.634\tAcc: 90.00%\n",
      "Step:     2\tLoss: 3.616\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.812\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.488\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.579\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.217\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.604\tAcc: 93.00%\n",
      "Step:     2\tLoss: 0.925\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.012\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.869\tAcc: 80.00%\n",
      "Step:     2\tLoss: 2.746\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.319\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.514\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.135\tAcc: 80.00%\n",
      "Step:     2\tLoss: 4.915\tAcc: 76.00%\n",
      "Step:     2\tLoss: 5.093\tAcc: 77.00%\n",
      "Step:     2\tLoss: 2.461\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.509\tAcc: 78.00%\n",
      "Step:     2\tLoss: 2.538\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.940\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.726\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.128\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.052\tAcc: 93.00%\n",
      "Step:     2\tLoss: 2.207\tAcc: 88.00%\n",
      "Step:     2\tLoss: 0.995\tAcc: 88.00%\n",
      "Step:     2\tLoss: 3.275\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.211\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.892\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.663\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.331\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.215\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.130\tAcc: 83.00%\n",
      "Step:     2\tLoss: 4.543\tAcc: 79.00%\n",
      "Step:     2\tLoss: 3.677\tAcc: 85.00%\n",
      "Step:     2\tLoss: 0.801\tAcc: 93.00%\n",
      "Step:     2\tLoss: 0.976\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.046\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.903\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.225\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.361\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.013\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.529\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.730\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.215\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.097\tAcc: 86.00%\n",
      "Step:     2\tLoss: 0.820\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.581\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.039\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.197\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.014\tAcc: 95.00%\n",
      "Step:     2\tLoss: 1.045\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.897\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.841\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.112\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.695\tAcc: 84.00%\n",
      "Step:     2\tLoss: 5.075\tAcc: 78.00%\n",
      "Step:     2\tLoss: 4.219\tAcc: 79.00%\n",
      "Step:     2\tLoss: 5.581\tAcc: 74.00%\n",
      "Step:     2\tLoss: 5.607\tAcc: 77.00%\n",
      "Step:     2\tLoss: 2.226\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.319\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.209\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.941\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.616\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.403\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.416\tAcc: 96.00%\n",
      "Step:     2\tLoss: 1.234\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.005\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.224\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.582\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.342\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.176\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.353\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.827\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.271\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.073\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.541\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.916\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.262\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.491\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.390\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.329\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.571\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.541\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.811\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.718\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.575\tAcc: 96.00%\n",
      "Step:     2\tLoss: 0.636\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.866\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.179\tAcc: 82.00%\n",
      "Step:     2\tLoss: 3.550\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.012\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.685\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.293\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.136\tAcc: 83.00%\n",
      "Step:     2\tLoss: 0.598\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.747\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.780\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.057\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.484\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.731\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.731\tAcc: 86.00%\n",
      "Step:     2\tLoss: 0.761\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.648\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.842\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.331\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.420\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.611\tAcc: 79.00%\n",
      "Step:     2\tLoss: 1.136\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.065\tAcc: 92.00%\n",
      "Step:     2\tLoss: 3.305\tAcc: 81.00%\n",
      "Step:     2\tLoss: 2.470\tAcc: 83.00%\n",
      "Step:     2\tLoss: 0.466\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.564\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.920\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.595\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.552\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.304\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.586\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.975\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.370\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.392\tAcc: 87.00%\n",
      "Step:     2\tLoss: 0.840\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.975\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.495\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.445\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.555\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.779\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.083\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.855\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.055\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.656\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.162\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.694\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.970\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.661\tAcc: 88.00%\n",
      "Step:     2\tLoss: 0.806\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.251\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.832\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.850\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.319\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.179\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.914\tAcc: 85.00%\n",
      "Step:     2\tLoss: 3.622\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.629\tAcc: 78.00%\n",
      "Step:     2\tLoss: 4.764\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.606\tAcc: 79.00%\n",
      "Step:     2\tLoss: 1.936\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.084\tAcc: 87.00%\n",
      "Step:     2\tLoss: 0.835\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.283\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.651\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.085\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.341\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.620\tAcc: 82.00%\n",
      "Step:     2\tLoss: 1.550\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.998\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.104\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.500\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.538\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.720\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.876\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.505\tAcc: 76.00%\n",
      "Step:     2\tLoss: 7.576\tAcc: 73.00%\n",
      "Step:     2\tLoss: 5.140\tAcc: 79.00%\n",
      "Step:     2\tLoss: 2.391\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.083\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.000\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.985\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.517\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.340\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.227\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.859\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.133\tAcc: 85.00%\n",
      "Step:     2\tLoss: 0.854\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.702\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.260\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.060\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.376\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.671\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.089\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.780\tAcc: 85.00%\n",
      "Step:     2\tLoss: 0.998\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.002\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.040\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.000\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.929\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.960\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.673\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.397\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.029\tAcc: 82.00%\n",
      "Step:     2\tLoss: 3.640\tAcc: 79.00%\n",
      "Step:     2\tLoss: 3.652\tAcc: 76.00%\n",
      "Step:     2\tLoss: 2.548\tAcc: 82.00%\n",
      "Step:     2\tLoss: 1.820\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.976\tAcc: 89.00%\n",
      "Step:     2\tLoss: 3.335\tAcc: 86.00%\n",
      "Step:     2\tLoss: 0.753\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.692\tAcc: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     2\tLoss: 1.531\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.916\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.228\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.280\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.963\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.501\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.850\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.087\tAcc: 81.00%\n",
      "Step:     2\tLoss: 4.469\tAcc: 81.00%\n",
      "Step:     2\tLoss: 3.329\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.363\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.642\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.531\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.071\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.931\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.872\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.595\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.250\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.532\tAcc: 93.00%\n",
      "Step:     2\tLoss: 0.876\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.022\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.133\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.538\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.919\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.208\tAcc: 96.00%\n",
      "Step:     2\tLoss: 1.367\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.557\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.534\tAcc: 90.00%\n",
      "Step:     2\tLoss: 3.073\tAcc: 83.00%\n",
      "Step:     2\tLoss: 3.175\tAcc: 79.00%\n",
      "Step:     2\tLoss: 1.858\tAcc: 82.00%\n",
      "Step:     2\tLoss: 1.595\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.963\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.300\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.938\tAcc: 80.00%\n",
      "Step:     2\tLoss: 1.111\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.602\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.219\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.681\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.508\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.933\tAcc: 85.00%\n",
      "Step:     2\tLoss: 4.744\tAcc: 74.00%\n",
      "Step:     2\tLoss: 4.421\tAcc: 82.00%\n",
      "Step:     2\tLoss: 3.123\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.456\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.405\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.792\tAcc: 95.00%\n",
      "Step:     2\tLoss: 1.864\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.449\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.060\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.941\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.187\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.300\tAcc: 89.00%\n",
      "Step:     2\tLoss: 4.078\tAcc: 81.00%\n",
      "Step:     2\tLoss: 4.132\tAcc: 78.00%\n",
      "Step:     2\tLoss: 7.565\tAcc: 65.00%\n",
      "Step:     2\tLoss: 14.669\tAcc: 73.00%\n",
      "Step:     2\tLoss: 9.587\tAcc: 69.00%\n",
      "Step:     2\tLoss: 3.902\tAcc: 79.00%\n",
      "Step:     2\tLoss: 4.345\tAcc: 78.00%\n",
      "Step:     2\tLoss: 4.623\tAcc: 79.00%\n",
      "Step:     2\tLoss: 3.138\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.456\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.499\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.377\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.732\tAcc: 93.00%\n",
      "Step:     2\tLoss: 2.685\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.252\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.821\tAcc: 89.00%\n",
      "Step:     2\tLoss: 3.978\tAcc: 78.00%\n",
      "Step:     2\tLoss: 2.500\tAcc: 83.00%\n",
      "Step:     2\tLoss: 3.489\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.649\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.392\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.142\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.735\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.852\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.519\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.047\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.434\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.231\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.830\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.573\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.811\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.163\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.829\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.478\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.015\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.563\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.192\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.579\tAcc: 82.00%\n",
      "Step:     2\tLoss: 5.026\tAcc: 77.00%\n",
      "Step:     2\tLoss: 4.834\tAcc: 77.00%\n",
      "Step:     2\tLoss: 5.749\tAcc: 79.00%\n",
      "Step:     2\tLoss: 2.157\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.351\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.334\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.870\tAcc: 88.00%\n",
      "Step:     2\tLoss: 3.318\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.041\tAcc: 85.00%\n",
      "Step:     2\tLoss: 4.255\tAcc: 80.00%\n",
      "Step:     2\tLoss: 3.112\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.547\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.343\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.596\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.048\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.119\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.193\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.924\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.617\tAcc: 84.00%\n",
      "Step:     2\tLoss: 0.643\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.719\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.455\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.061\tAcc: 87.00%\n",
      "Step:     2\tLoss: 0.553\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.398\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.893\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.754\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.771\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.204\tAcc: 92.00%\n",
      "Step:     2\tLoss: 0.917\tAcc: 91.00%\n",
      "Step:     2\tLoss: 3.763\tAcc: 76.00%\n",
      "Step:     2\tLoss: 3.185\tAcc: 78.00%\n",
      "Step:     2\tLoss: 2.798\tAcc: 83.00%\n",
      "Step:     2\tLoss: 1.321\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.318\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.484\tAcc: 81.00%\n",
      "Step:     2\tLoss: 1.126\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.791\tAcc: 95.00%\n",
      "Step:     2\tLoss: 1.831\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.469\tAcc: 92.00%\n",
      "Step:     2\tLoss: 3.003\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.796\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.809\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.027\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.995\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.408\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.491\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.658\tAcc: 88.00%\n",
      "Step:     2\tLoss: 0.742\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.531\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.974\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.688\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.886\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.438\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.779\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.894\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.804\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.193\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.292\tAcc: 87.00%\n",
      "Step:     2\tLoss: 0.889\tAcc: 93.00%\n",
      "Step:     2\tLoss: 2.151\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.647\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.815\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.765\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.291\tAcc: 96.00%\n",
      "Step:     2\tLoss: 0.625\tAcc: 94.00%\n",
      "Step:     2\tLoss: 1.337\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.891\tAcc: 90.00%\n",
      "Step:     2\tLoss: 3.731\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.189\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.398\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.844\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.229\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.330\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.570\tAcc: 87.00%\n",
      "Step:     2\tLoss: 3.742\tAcc: 81.00%\n",
      "Step:     2\tLoss: 2.303\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.571\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.799\tAcc: 93.00%\n",
      "Step:     2\tLoss: 2.145\tAcc: 93.00%\n",
      "Step:     2\tLoss: 0.314\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.174\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.977\tAcc: 82.00%\n",
      "Step:     2\tLoss: 2.409\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.108\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.958\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.829\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.061\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.439\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.690\tAcc: 94.00%\n",
      "Step:     2\tLoss: 0.926\tAcc: 94.00%\n",
      "Step:     2\tLoss: 2.177\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.250\tAcc: 89.00%\n",
      "Step:     2\tLoss: 1.121\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.117\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.685\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.522\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.543\tAcc: 93.00%\n",
      "Step:     2\tLoss: 2.556\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.119\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.652\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.958\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.888\tAcc: 78.00%\n",
      "Step:     2\tLoss: 2.902\tAcc: 84.00%\n",
      "Step:     2\tLoss: 3.702\tAcc: 79.00%\n",
      "Step:     2\tLoss: 1.000\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.338\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.855\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.478\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.800\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.346\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.851\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.121\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.476\tAcc: 90.00%\n",
      "Step:     2\tLoss: 0.814\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.347\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.985\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.571\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.811\tAcc: 87.00%\n",
      "Step:     2\tLoss: 5.052\tAcc: 77.00%\n",
      "Step:     2\tLoss: 8.731\tAcc: 66.00%\n",
      "Step:     2\tLoss: 8.186\tAcc: 80.00%\n",
      "Step:     2\tLoss: 4.635\tAcc: 84.00%\n",
      "Step:     2\tLoss: 2.448\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.248\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.624\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.052\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.208\tAcc: 91.00%\n",
      "Step:     2\tLoss: 2.068\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.553\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.065\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.701\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.059\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.778\tAcc: 88.00%\n",
      "Step:     2\tLoss: 2.337\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.695\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.523\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.515\tAcc: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     2\tLoss: 1.345\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.392\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.117\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.478\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.476\tAcc: 84.00%\n",
      "Step:     2\tLoss: 1.658\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.828\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.857\tAcc: 81.00%\n",
      "Step:     2\tLoss: 4.159\tAcc: 75.00%\n",
      "Step:     2\tLoss: 2.371\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.244\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.283\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.811\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.107\tAcc: 90.00%\n",
      "Step:     2\tLoss: 1.347\tAcc: 92.00%\n",
      "Step:     2\tLoss: 2.196\tAcc: 86.00%\n",
      "Step:     2\tLoss: 1.764\tAcc: 86.00%\n",
      "Step:     2\tLoss: 2.144\tAcc: 89.00%\n",
      "Step:     2\tLoss: 2.714\tAcc: 85.00%\n",
      "Step:     2\tLoss: 7.291\tAcc: 76.00%\n",
      "Step:     2\tLoss: 2.123\tAcc: 83.00%\n",
      "Step:     2\tLoss: 3.929\tAcc: 81.00%\n",
      "Step:     2\tLoss: 2.278\tAcc: 90.00%\n",
      "Step:     2\tLoss: 2.350\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.666\tAcc: 91.00%\n",
      "Step:     2\tLoss: 0.976\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.209\tAcc: 92.00%\n",
      "Step:     2\tLoss: 1.306\tAcc: 89.00%\n",
      "Step:     2\tLoss: 3.459\tAcc: 83.00%\n",
      "Step:     2\tLoss: 2.175\tAcc: 88.00%\n",
      "Step:     2\tLoss: 1.970\tAcc: 86.00%\n",
      "Step:     2\tLoss: 3.749\tAcc: 87.00%\n",
      "Step:     2\tLoss: 2.549\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.116\tAcc: 93.00%\n",
      "Step:     2\tLoss: 1.162\tAcc: 91.00%\n",
      "Step:     2\tLoss: 3.064\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.609\tAcc: 85.00%\n",
      "Step:     2\tLoss: 2.204\tAcc: 89.00%\n",
      "Step:     2\tLoss: 0.487\tAcc: 95.00%\n",
      "Step:     2\tLoss: 2.847\tAcc: 87.00%\n",
      "Step:     2\tLoss: 1.790\tAcc: 85.00%\n",
      "Step:     2\tLoss: 1.372\tAcc: 91.00%\n",
      "Step:     2\tLoss: 1.408\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.605\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.889\tAcc: 85.00%\n",
      "Step:     3\tLoss: 0.984\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.982\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.620\tAcc: 87.00%\n",
      "Step:     3\tLoss: 3.779\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.162\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.193\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.348\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.578\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.975\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.033\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.473\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.849\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.067\tAcc: 82.00%\n",
      "Step:     3\tLoss: 1.179\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.446\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.827\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.360\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.029\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.374\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.509\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.689\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.872\tAcc: 88.00%\n",
      "Step:     3\tLoss: 0.665\tAcc: 97.00%\n",
      "Step:     3\tLoss: 1.212\tAcc: 94.00%\n",
      "Step:     3\tLoss: 2.920\tAcc: 89.00%\n",
      "Step:     3\tLoss: 4.966\tAcc: 78.00%\n",
      "Step:     3\tLoss: 3.195\tAcc: 84.00%\n",
      "Step:     3\tLoss: 0.648\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.741\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.325\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.793\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.758\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.206\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.107\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.078\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.503\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.507\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.071\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.626\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.851\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.983\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.174\tAcc: 80.00%\n",
      "Step:     3\tLoss: 5.143\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.684\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.913\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.613\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.001\tAcc: 92.00%\n",
      "Step:     3\tLoss: 3.591\tAcc: 84.00%\n",
      "Step:     3\tLoss: 0.673\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.626\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.058\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.823\tAcc: 96.00%\n",
      "Step:     3\tLoss: 0.543\tAcc: 95.00%\n",
      "Step:     3\tLoss: 2.144\tAcc: 91.00%\n",
      "Step:     3\tLoss: 3.040\tAcc: 88.00%\n",
      "Step:     3\tLoss: 3.969\tAcc: 82.00%\n",
      "Step:     3\tLoss: 1.709\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.838\tAcc: 88.00%\n",
      "Step:     3\tLoss: 3.128\tAcc: 78.00%\n",
      "Step:     3\tLoss: 0.764\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.135\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.097\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.028\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.005\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.121\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.467\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.031\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.979\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.261\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.419\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.617\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.133\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.526\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.058\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.635\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.338\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.895\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.010\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.143\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.832\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.633\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.017\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.095\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.607\tAcc: 81.00%\n",
      "Step:     3\tLoss: 1.730\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.053\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.230\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.769\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.314\tAcc: 82.00%\n",
      "Step:     3\tLoss: 0.766\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.788\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.414\tAcc: 96.00%\n",
      "Step:     3\tLoss: 2.814\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.703\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.619\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.534\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.992\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.959\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.299\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.178\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.745\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.510\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.965\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.798\tAcc: 73.00%\n",
      "Step:     3\tLoss: 2.429\tAcc: 88.00%\n",
      "Step:     3\tLoss: 3.448\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.633\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.567\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.364\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.862\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.329\tAcc: 96.00%\n",
      "Step:     3\tLoss: 1.084\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.964\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.228\tAcc: 81.00%\n",
      "Step:     3\tLoss: 1.574\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.909\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.416\tAcc: 83.00%\n",
      "Step:     3\tLoss: 3.890\tAcc: 75.00%\n",
      "Step:     3\tLoss: 7.449\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.848\tAcc: 86.00%\n",
      "Step:     3\tLoss: 3.342\tAcc: 81.00%\n",
      "Step:     3\tLoss: 0.835\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.568\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.895\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.995\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.128\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.407\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.617\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.722\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.792\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.453\tAcc: 82.00%\n",
      "Step:     3\tLoss: 2.657\tAcc: 79.00%\n",
      "Step:     3\tLoss: 4.187\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.121\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.919\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.714\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.709\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.334\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.253\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.106\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.161\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.025\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.348\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.268\tAcc: 94.00%\n",
      "Step:     3\tLoss: 2.326\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.141\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.243\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.841\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.472\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.368\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.090\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.770\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.805\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.321\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.055\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.468\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.177\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.884\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.714\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.126\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.375\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.298\tAcc: 87.00%\n",
      "Step:     3\tLoss: 4.608\tAcc: 71.00%\n",
      "Step:     3\tLoss: 10.173\tAcc: 73.00%\n",
      "Step:     3\tLoss: 5.066\tAcc: 75.00%\n",
      "Step:     3\tLoss: 6.790\tAcc: 69.00%\n",
      "Step:     3\tLoss: 3.369\tAcc: 79.00%\n",
      "Step:     3\tLoss: 2.010\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.662\tAcc: 83.00%\n",
      "Step:     3\tLoss: 3.871\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.010\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.746\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.419\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.622\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.538\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.334\tAcc: 83.00%\n",
      "Step:     3\tLoss: 3.008\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.035\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.276\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.538\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.831\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.708\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.617\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.305\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.112\tAcc: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     3\tLoss: 0.981\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.080\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.957\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.738\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.013\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.799\tAcc: 87.00%\n",
      "Step:     3\tLoss: 3.505\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.599\tAcc: 83.00%\n",
      "Step:     3\tLoss: 0.993\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.173\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.920\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.760\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.372\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.637\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.056\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.956\tAcc: 87.00%\n",
      "Step:     3\tLoss: 3.025\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.360\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.958\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.022\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.196\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.383\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.573\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.983\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.182\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.831\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.881\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.310\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.811\tAcc: 77.00%\n",
      "Step:     3\tLoss: 4.285\tAcc: 76.00%\n",
      "Step:     3\tLoss: 5.355\tAcc: 82.00%\n",
      "Step:     3\tLoss: 0.952\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.403\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.668\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.725\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.394\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.167\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.936\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.740\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.489\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.637\tAcc: 83.00%\n",
      "Step:     3\tLoss: 3.991\tAcc: 80.00%\n",
      "Step:     3\tLoss: 2.961\tAcc: 81.00%\n",
      "Step:     3\tLoss: 1.026\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.305\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.848\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.818\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.543\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.839\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.136\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.250\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.103\tAcc: 95.00%\n",
      "Step:     3\tLoss: 0.942\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.444\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.900\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.544\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.981\tAcc: 91.00%\n",
      "Step:     3\tLoss: 3.124\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.257\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.203\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.807\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.866\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.905\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.750\tAcc: 96.00%\n",
      "Step:     3\tLoss: 0.680\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.871\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.719\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.422\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.529\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.983\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.007\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.052\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.883\tAcc: 95.00%\n",
      "Step:     3\tLoss: 1.843\tAcc: 88.00%\n",
      "Step:     3\tLoss: 0.991\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.453\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.776\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.434\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.565\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.970\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.515\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.716\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.998\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.362\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.050\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.869\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.644\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.754\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.835\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.690\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.203\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.262\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.371\tAcc: 78.00%\n",
      "Step:     3\tLoss: 5.021\tAcc: 78.00%\n",
      "Step:     3\tLoss: 2.901\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.009\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.422\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.758\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.348\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.286\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.604\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.688\tAcc: 80.00%\n",
      "Step:     3\tLoss: 3.897\tAcc: 80.00%\n",
      "Step:     3\tLoss: 2.017\tAcc: 83.00%\n",
      "Step:     3\tLoss: 1.389\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.771\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.037\tAcc: 95.00%\n",
      "Step:     3\tLoss: 1.983\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.513\tAcc: 84.00%\n",
      "Step:     3\tLoss: 4.522\tAcc: 82.00%\n",
      "Step:     3\tLoss: 2.532\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.549\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.110\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.093\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.190\tAcc: 93.00%\n",
      "Step:     3\tLoss: 3.751\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.452\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.874\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.819\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.185\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.340\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.940\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.473\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.087\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.868\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.642\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.938\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.894\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.030\tAcc: 90.00%\n",
      "Step:     3\tLoss: 2.046\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.529\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.245\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.595\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.049\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.766\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.019\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.565\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.686\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.157\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.300\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.281\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.059\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.034\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.357\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.895\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.765\tAcc: 91.00%\n",
      "Step:     3\tLoss: 3.913\tAcc: 82.00%\n",
      "Step:     3\tLoss: 2.029\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.801\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.620\tAcc: 88.00%\n",
      "Step:     3\tLoss: 0.350\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.462\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.784\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.156\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.999\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.599\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.321\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.335\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.367\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.801\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.837\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.451\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.923\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.202\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.818\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.144\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.085\tAcc: 84.00%\n",
      "Step:     3\tLoss: 1.603\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.889\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.053\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.115\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.190\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.864\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.035\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.619\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.137\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.209\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.782\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.231\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.421\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.236\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.237\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.504\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.198\tAcc: 88.00%\n",
      "Step:     3\tLoss: 0.788\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.282\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.920\tAcc: 85.00%\n",
      "Step:     3\tLoss: 3.423\tAcc: 79.00%\n",
      "Step:     3\tLoss: 4.986\tAcc: 76.00%\n",
      "Step:     3\tLoss: 5.539\tAcc: 73.00%\n",
      "Step:     3\tLoss: 3.948\tAcc: 81.00%\n",
      "Step:     3\tLoss: 1.043\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.092\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.894\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.833\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.547\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.598\tAcc: 85.00%\n",
      "Step:     3\tLoss: 4.395\tAcc: 80.00%\n",
      "Step:     3\tLoss: 3.712\tAcc: 80.00%\n",
      "Step:     3\tLoss: 6.306\tAcc: 69.00%\n",
      "Step:     3\tLoss: 8.724\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.444\tAcc: 76.00%\n",
      "Step:     3\tLoss: 2.160\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.298\tAcc: 82.00%\n",
      "Step:     3\tLoss: 5.183\tAcc: 78.00%\n",
      "Step:     3\tLoss: 3.086\tAcc: 86.00%\n",
      "Step:     3\tLoss: 4.219\tAcc: 81.00%\n",
      "Step:     3\tLoss: 3.234\tAcc: 79.00%\n",
      "Step:     3\tLoss: 2.963\tAcc: 81.00%\n",
      "Step:     3\tLoss: 6.623\tAcc: 77.00%\n",
      "Step:     3\tLoss: 4.129\tAcc: 78.00%\n",
      "Step:     3\tLoss: 2.310\tAcc: 79.00%\n",
      "Step:     3\tLoss: 2.170\tAcc: 84.00%\n",
      "Step:     3\tLoss: 2.745\tAcc: 91.00%\n",
      "Step:     3\tLoss: 3.315\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.641\tAcc: 83.00%\n",
      "Step:     3\tLoss: 3.711\tAcc: 80.00%\n",
      "Step:     3\tLoss: 2.092\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.021\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.743\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.387\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.447\tAcc: 82.00%\n",
      "Step:     3\tLoss: 1.746\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.101\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.883\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.091\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.341\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.625\tAcc: 87.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     3\tLoss: 2.249\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.390\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.962\tAcc: 79.00%\n",
      "Step:     3\tLoss: 3.699\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.145\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.757\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.188\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.705\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.731\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.373\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.675\tAcc: 95.00%\n",
      "Step:     3\tLoss: 0.843\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.818\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.331\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.352\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.433\tAcc: 95.00%\n",
      "Step:     3\tLoss: 1.513\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.381\tAcc: 96.00%\n",
      "Step:     3\tLoss: 2.073\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.410\tAcc: 96.00%\n",
      "Step:     3\tLoss: 1.403\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.800\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.485\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.254\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.248\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.694\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.170\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.822\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.596\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.653\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.095\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.593\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.717\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.369\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.873\tAcc: 95.00%\n",
      "Step:     3\tLoss: 1.574\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.355\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.262\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.305\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.570\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.977\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.862\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.972\tAcc: 82.00%\n",
      "Step:     3\tLoss: 3.495\tAcc: 78.00%\n",
      "Step:     3\tLoss: 3.573\tAcc: 79.00%\n",
      "Step:     3\tLoss: 2.083\tAcc: 89.00%\n",
      "Step:     3\tLoss: 3.352\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.803\tAcc: 82.00%\n",
      "Step:     3\tLoss: 2.101\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.606\tAcc: 94.00%\n",
      "Step:     3\tLoss: 0.689\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.004\tAcc: 93.00%\n",
      "Step:     3\tLoss: 0.817\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.267\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.443\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.181\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.314\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.534\tAcc: 94.00%\n",
      "Step:     3\tLoss: 3.347\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.445\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.337\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.968\tAcc: 85.00%\n",
      "Step:     3\tLoss: 0.985\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.550\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.876\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.643\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.561\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.699\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.232\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.970\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.539\tAcc: 84.00%\n",
      "Step:     3\tLoss: 0.631\tAcc: 93.00%\n",
      "Step:     3\tLoss: 1.066\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.834\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.460\tAcc: 96.00%\n",
      "Step:     3\tLoss: 1.301\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.336\tAcc: 90.00%\n",
      "Step:     3\tLoss: 0.658\tAcc: 94.00%\n",
      "Step:     3\tLoss: 1.306\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.778\tAcc: 87.00%\n",
      "Step:     3\tLoss: 2.380\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.412\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.791\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.585\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.097\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.055\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.545\tAcc: 88.00%\n",
      "Step:     3\tLoss: 3.847\tAcc: 79.00%\n",
      "Step:     3\tLoss: 4.015\tAcc: 80.00%\n",
      "Step:     3\tLoss: 3.408\tAcc: 81.00%\n",
      "Step:     3\tLoss: 2.719\tAcc: 81.00%\n",
      "Step:     3\tLoss: 6.131\tAcc: 73.00%\n",
      "Step:     3\tLoss: 4.576\tAcc: 74.00%\n",
      "Step:     3\tLoss: 4.916\tAcc: 80.00%\n",
      "Step:     3\tLoss: 1.239\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.511\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.973\tAcc: 92.00%\n",
      "Step:     3\tLoss: 0.954\tAcc: 91.00%\n",
      "Step:     3\tLoss: 0.808\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.947\tAcc: 85.00%\n",
      "Step:     3\tLoss: 2.917\tAcc: 81.00%\n",
      "Step:     3\tLoss: 4.864\tAcc: 81.00%\n",
      "Step:     3\tLoss: 1.436\tAcc: 88.00%\n",
      "Step:     3\tLoss: 2.977\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.491\tAcc: 92.00%\n",
      "Step:     3\tLoss: 2.107\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.230\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.761\tAcc: 89.00%\n",
      "Step:     3\tLoss: 0.909\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.891\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.364\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.859\tAcc: 87.00%\n",
      "Step:     3\tLoss: 1.455\tAcc: 88.00%\n",
      "Step:     3\tLoss: 1.900\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.354\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.590\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.320\tAcc: 89.00%\n",
      "Step:     3\tLoss: 2.677\tAcc: 83.00%\n",
      "Step:     3\tLoss: 2.949\tAcc: 83.00%\n",
      "Step:     3\tLoss: 4.810\tAcc: 78.00%\n",
      "Step:     3\tLoss: 3.744\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.070\tAcc: 92.00%\n",
      "Step:     3\tLoss: 1.295\tAcc: 91.00%\n",
      "Step:     3\tLoss: 2.519\tAcc: 89.00%\n",
      "Step:     3\tLoss: 1.250\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.437\tAcc: 86.00%\n",
      "Step:     3\tLoss: 0.785\tAcc: 90.00%\n",
      "Step:     3\tLoss: 1.424\tAcc: 91.00%\n",
      "Step:     3\tLoss: 1.765\tAcc: 85.00%\n",
      "Step:     3\tLoss: 1.836\tAcc: 86.00%\n",
      "Step:     3\tLoss: 1.413\tAcc: 87.00%\n",
      "Step:     3\tLoss: 0.696\tAcc: 93.00%\n",
      "Step:     3\tLoss: 2.503\tAcc: 90.00%\n",
      "Step:     3\tLoss: 3.662\tAcc: 86.00%\n",
      "Step:     3\tLoss: 2.209\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.513\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.244\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.344\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.275\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.726\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.364\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.756\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.106\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.394\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.592\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.589\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.812\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.734\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.264\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.404\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.973\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.709\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.267\tAcc: 87.00%\n",
      "Step:     4\tLoss: 3.362\tAcc: 82.00%\n",
      "Step:     4\tLoss: 4.982\tAcc: 68.00%\n",
      "Step:     4\tLoss: 8.285\tAcc: 81.00%\n",
      "Step:     4\tLoss: 2.867\tAcc: 80.00%\n",
      "Step:     4\tLoss: 3.565\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.802\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.052\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.438\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.566\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.144\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.906\tAcc: 94.00%\n",
      "Step:     4\tLoss: 2.447\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.598\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.856\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.446\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.467\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.291\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.494\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.022\tAcc: 87.00%\n",
      "Step:     4\tLoss: 0.809\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.205\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.348\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.441\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.817\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.221\tAcc: 95.00%\n",
      "Step:     4\tLoss: 2.010\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.514\tAcc: 87.00%\n",
      "Step:     4\tLoss: 3.387\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.936\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.797\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.395\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.770\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.725\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.155\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.877\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.152\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.345\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.057\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.358\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.584\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.957\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.473\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.763\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.012\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.495\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.999\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.186\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.258\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.916\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.167\tAcc: 84.00%\n",
      "Step:     4\tLoss: 6.426\tAcc: 72.00%\n",
      "Step:     4\tLoss: 12.760\tAcc: 65.00%\n",
      "Step:     4\tLoss: 9.398\tAcc: 67.00%\n",
      "Step:     4\tLoss: 12.714\tAcc: 65.00%\n",
      "Step:     4\tLoss: 11.161\tAcc: 79.00%\n",
      "Step:     4\tLoss: 2.475\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.655\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.134\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.289\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.907\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.653\tAcc: 83.00%\n",
      "Step:     4\tLoss: 1.214\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.657\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.690\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.707\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.687\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.270\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.368\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.522\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.633\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.722\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.089\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.056\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.880\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.606\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.969\tAcc: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     4\tLoss: 0.706\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.919\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.932\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.903\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.551\tAcc: 81.00%\n",
      "Step:     4\tLoss: 3.201\tAcc: 79.00%\n",
      "Step:     4\tLoss: 1.027\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.344\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.876\tAcc: 94.00%\n",
      "Step:     4\tLoss: 2.176\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.727\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.218\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.376\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.303\tAcc: 92.00%\n",
      "Step:     4\tLoss: 3.684\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.284\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.914\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.083\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.948\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.852\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.875\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.689\tAcc: 94.00%\n",
      "Step:     4\tLoss: 2.680\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.407\tAcc: 94.00%\n",
      "Step:     4\tLoss: 2.238\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.263\tAcc: 83.00%\n",
      "Step:     4\tLoss: 0.951\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.494\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.054\tAcc: 85.00%\n",
      "Step:     4\tLoss: 0.892\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.656\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.504\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.130\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.724\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.754\tAcc: 83.00%\n",
      "Step:     4\tLoss: 3.002\tAcc: 78.00%\n",
      "Step:     4\tLoss: 4.722\tAcc: 75.00%\n",
      "Step:     4\tLoss: 2.827\tAcc: 81.00%\n",
      "Step:     4\tLoss: 2.411\tAcc: 81.00%\n",
      "Step:     4\tLoss: 3.063\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.450\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.621\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.821\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.972\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.395\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.445\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.839\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.994\tAcc: 82.00%\n",
      "Step:     4\tLoss: 4.711\tAcc: 83.00%\n",
      "Step:     4\tLoss: 3.235\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.874\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.961\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.259\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.106\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.346\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.861\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.699\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.367\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.306\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.234\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.745\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.001\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.619\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.610\tAcc: 93.00%\n",
      "Step:     4\tLoss: 0.279\tAcc: 99.00%\n",
      "Step:     4\tLoss: 1.312\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.174\tAcc: 89.00%\n",
      "Step:     4\tLoss: 3.300\tAcc: 83.00%\n",
      "Step:     4\tLoss: 1.788\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.416\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.580\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.759\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.365\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.248\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.200\tAcc: 95.00%\n",
      "Step:     4\tLoss: 0.546\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.486\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.917\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.217\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.434\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.619\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.076\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.680\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.352\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.545\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.915\tAcc: 83.00%\n",
      "Step:     4\tLoss: 1.839\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.014\tAcc: 80.00%\n",
      "Step:     4\tLoss: 2.524\tAcc: 81.00%\n",
      "Step:     4\tLoss: 2.878\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.303\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.414\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.266\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.861\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.686\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.698\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.169\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.555\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.231\tAcc: 96.00%\n",
      "Step:     4\tLoss: 0.661\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.356\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.358\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.802\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.873\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.863\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.576\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.396\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.343\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.827\tAcc: 93.00%\n",
      "Step:     4\tLoss: 0.558\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.867\tAcc: 95.00%\n",
      "Step:     4\tLoss: 2.055\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.623\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.058\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.840\tAcc: 79.00%\n",
      "Step:     4\tLoss: 1.610\tAcc: 87.00%\n",
      "Step:     4\tLoss: 0.575\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.539\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.839\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.391\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.921\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.546\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.975\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.665\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.682\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.324\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.825\tAcc: 86.00%\n",
      "Step:     4\tLoss: 0.590\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.890\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.546\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.383\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.287\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.285\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.805\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.659\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.454\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.931\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.186\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.382\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.680\tAcc: 77.00%\n",
      "Step:     4\tLoss: 8.356\tAcc: 66.00%\n",
      "Step:     4\tLoss: 8.624\tAcc: 72.00%\n",
      "Step:     4\tLoss: 3.019\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.758\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.922\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.833\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.825\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.411\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.262\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.321\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.977\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.267\tAcc: 87.00%\n",
      "Step:     4\tLoss: 3.174\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.321\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.983\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.036\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.446\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.359\tAcc: 89.00%\n",
      "Step:     4\tLoss: 3.617\tAcc: 82.00%\n",
      "Step:     4\tLoss: 4.351\tAcc: 72.00%\n",
      "Step:     4\tLoss: 4.637\tAcc: 76.00%\n",
      "Step:     4\tLoss: 1.719\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.636\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.621\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.604\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.593\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.022\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.148\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.157\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.848\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.568\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.137\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.769\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.839\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.006\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.497\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.400\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.415\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.085\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.199\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.274\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.892\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.365\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.219\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.345\tAcc: 93.00%\n",
      "Step:     4\tLoss: 0.916\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.250\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.561\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.808\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.209\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.561\tAcc: 87.00%\n",
      "Step:     4\tLoss: 3.625\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.600\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.287\tAcc: 92.00%\n",
      "Step:     4\tLoss: 3.111\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.782\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.440\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.687\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.426\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.263\tAcc: 87.00%\n",
      "Step:     4\tLoss: 0.745\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.325\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.507\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.177\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.924\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.675\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.354\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.614\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.531\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.238\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.581\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.321\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.158\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.907\tAcc: 83.00%\n",
      "Step:     4\tLoss: 3.582\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.648\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.305\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.721\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.647\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.971\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.118\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.916\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.698\tAcc: 83.00%\n",
      "Step:     4\tLoss: 4.645\tAcc: 73.00%\n",
      "Step:     4\tLoss: 7.291\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.795\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.314\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.227\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.741\tAcc: 87.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     4\tLoss: 1.768\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.425\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.277\tAcc: 91.00%\n",
      "Step:     4\tLoss: 3.181\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.269\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.816\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.013\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.046\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.763\tAcc: 84.00%\n",
      "Step:     4\tLoss: 5.210\tAcc: 80.00%\n",
      "Step:     4\tLoss: 4.288\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.184\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.449\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.033\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.829\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.469\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.034\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.372\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.196\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.919\tAcc: 86.00%\n",
      "Step:     4\tLoss: 0.647\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.777\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.859\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.570\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.483\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.251\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.800\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.567\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.994\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.576\tAcc: 85.00%\n",
      "Step:     4\tLoss: 3.178\tAcc: 79.00%\n",
      "Step:     4\tLoss: 2.397\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.033\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.559\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.457\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.233\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.188\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.192\tAcc: 95.00%\n",
      "Step:     4\tLoss: 0.424\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.483\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.005\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.162\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.104\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.104\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.067\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.866\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.991\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.610\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.166\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.532\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.117\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.264\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.444\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.492\tAcc: 82.00%\n",
      "Step:     4\tLoss: 0.372\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.341\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.959\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.434\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.836\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.505\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.094\tAcc: 88.00%\n",
      "Step:     4\tLoss: 4.091\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.838\tAcc: 85.00%\n",
      "Step:     4\tLoss: 0.967\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.568\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.352\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.348\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.001\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.665\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.944\tAcc: 85.00%\n",
      "Step:     4\tLoss: 0.892\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.212\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.645\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.838\tAcc: 85.00%\n",
      "Step:     4\tLoss: 0.776\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.793\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.404\tAcc: 96.00%\n",
      "Step:     4\tLoss: 0.801\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.497\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.653\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.693\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.551\tAcc: 86.00%\n",
      "Step:     4\tLoss: 0.879\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.206\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.404\tAcc: 96.00%\n",
      "Step:     4\tLoss: 1.164\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.408\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.378\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.390\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.018\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.994\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.915\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.383\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.392\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.635\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.441\tAcc: 85.00%\n",
      "Step:     4\tLoss: 0.724\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.992\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.692\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.965\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.109\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.930\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.928\tAcc: 85.00%\n",
      "Step:     4\tLoss: 1.747\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.829\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.947\tAcc: 95.00%\n",
      "Step:     4\tLoss: 1.861\tAcc: 87.00%\n",
      "Step:     4\tLoss: 0.893\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.911\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.673\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.048\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.600\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.254\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.347\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.693\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.231\tAcc: 94.00%\n",
      "Step:     4\tLoss: 0.682\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.605\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.243\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.927\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.133\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.163\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.903\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.118\tAcc: 85.00%\n",
      "Step:     4\tLoss: 3.095\tAcc: 79.00%\n",
      "Step:     4\tLoss: 3.059\tAcc: 84.00%\n",
      "Step:     4\tLoss: 3.577\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.245\tAcc: 84.00%\n",
      "Step:     4\tLoss: 5.213\tAcc: 78.00%\n",
      "Step:     4\tLoss: 1.054\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.409\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.014\tAcc: 83.00%\n",
      "Step:     4\tLoss: 3.054\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.203\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.954\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.569\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.705\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.760\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.018\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.537\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.039\tAcc: 92.00%\n",
      "Step:     4\tLoss: 2.200\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.640\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.479\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.789\tAcc: 86.00%\n",
      "Step:     4\tLoss: 2.105\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.852\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.524\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.415\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.970\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.872\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.138\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.688\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.564\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.875\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.065\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.957\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.485\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.835\tAcc: 79.00%\n",
      "Step:     4\tLoss: 1.716\tAcc: 84.00%\n",
      "Step:     4\tLoss: 1.862\tAcc: 90.00%\n",
      "Step:     4\tLoss: 0.910\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.087\tAcc: 86.00%\n",
      "Step:     4\tLoss: 1.457\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.776\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.394\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.428\tAcc: 80.00%\n",
      "Step:     4\tLoss: 1.958\tAcc: 81.00%\n",
      "Step:     4\tLoss: 1.992\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.896\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.001\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.587\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.378\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.436\tAcc: 92.00%\n",
      "Step:     4\tLoss: 0.758\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.725\tAcc: 91.00%\n",
      "Step:     4\tLoss: 2.113\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.245\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.553\tAcc: 89.00%\n",
      "Step:     4\tLoss: 1.440\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.965\tAcc: 89.00%\n",
      "Step:     4\tLoss: 0.991\tAcc: 92.00%\n",
      "Step:     4\tLoss: 1.240\tAcc: 90.00%\n",
      "Step:     4\tLoss: 2.145\tAcc: 88.00%\n",
      "Step:     4\tLoss: 3.317\tAcc: 87.00%\n",
      "Step:     4\tLoss: 2.477\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.251\tAcc: 88.00%\n",
      "Step:     4\tLoss: 2.335\tAcc: 85.00%\n",
      "Step:     4\tLoss: 5.349\tAcc: 76.00%\n",
      "Step:     4\tLoss: 4.650\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.486\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.387\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.433\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.175\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.710\tAcc: 88.00%\n",
      "Step:     4\tLoss: 0.924\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.981\tAcc: 94.00%\n",
      "Step:     4\tLoss: 1.084\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.882\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.368\tAcc: 80.00%\n",
      "Step:     4\tLoss: 3.810\tAcc: 86.00%\n",
      "Step:     4\tLoss: 3.173\tAcc: 74.00%\n",
      "Step:     4\tLoss: 6.276\tAcc: 70.00%\n",
      "Step:     4\tLoss: 3.008\tAcc: 89.00%\n",
      "Step:     4\tLoss: 2.999\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.520\tAcc: 84.00%\n",
      "Step:     4\tLoss: 0.484\tAcc: 93.00%\n",
      "Step:     4\tLoss: 1.626\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.710\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.483\tAcc: 91.00%\n",
      "Step:     4\tLoss: 1.629\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.695\tAcc: 82.00%\n",
      "Step:     4\tLoss: 2.012\tAcc: 87.00%\n",
      "Step:     4\tLoss: 1.756\tAcc: 90.00%\n",
      "Step:     4\tLoss: 1.478\tAcc: 88.00%\n",
      "Step:     4\tLoss: 1.001\tAcc: 93.00%\n",
      "Step:     4\tLoss: 2.404\tAcc: 82.00%\n",
      "Step:     4\tLoss: 4.104\tAcc: 81.00%\n",
      "Step:     4\tLoss: 3.182\tAcc: 83.00%\n",
      "Step:     4\tLoss: 2.787\tAcc: 85.00%\n",
      "Step:     4\tLoss: 2.517\tAcc: 81.00%\n",
      "Step:     4\tLoss: 4.178\tAcc: 82.00%\n",
      "Step:     4\tLoss: 1.315\tAcc: 91.00%\n",
      "Step:     4\tLoss: 0.544\tAcc: 92.00%\n",
      "Step:     4\tLoss: 3.331\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.757\tAcc: 84.00%\n",
      "Step:     4\tLoss: 2.003\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.517\tAcc: 87.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     5\tLoss: 2.789\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.454\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.038\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.089\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.354\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.748\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.603\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.267\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.701\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.550\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.754\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.210\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.238\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.853\tAcc: 82.00%\n",
      "Step:     5\tLoss: 2.768\tAcc: 87.00%\n",
      "Step:     5\tLoss: 3.971\tAcc: 79.00%\n",
      "Step:     5\tLoss: 3.521\tAcc: 71.00%\n",
      "Step:     5\tLoss: 7.568\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.961\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.968\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.229\tAcc: 91.00%\n",
      "Step:     5\tLoss: 3.569\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.020\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.493\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.061\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.369\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.374\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.741\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.925\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.984\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.613\tAcc: 81.00%\n",
      "Step:     5\tLoss: 4.586\tAcc: 78.00%\n",
      "Step:     5\tLoss: 4.053\tAcc: 82.00%\n",
      "Step:     5\tLoss: 2.219\tAcc: 84.00%\n",
      "Step:     5\tLoss: 3.473\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.798\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.641\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.854\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.830\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.048\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.137\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.290\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.703\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.192\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.677\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.271\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.164\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.409\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.747\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.599\tAcc: 94.00%\n",
      "Step:     5\tLoss: 2.074\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.152\tAcc: 95.00%\n",
      "Step:     5\tLoss: 0.848\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.385\tAcc: 83.00%\n",
      "Step:     5\tLoss: 2.929\tAcc: 81.00%\n",
      "Step:     5\tLoss: 4.553\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.807\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.437\tAcc: 84.00%\n",
      "Step:     5\tLoss: 3.887\tAcc: 81.00%\n",
      "Step:     5\tLoss: 3.928\tAcc: 83.00%\n",
      "Step:     5\tLoss: 2.049\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.775\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.900\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.302\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.896\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.751\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.749\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.649\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.771\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.308\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.384\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.058\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.947\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.742\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.168\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.649\tAcc: 91.00%\n",
      "Step:     5\tLoss: 3.411\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.463\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.494\tAcc: 87.00%\n",
      "Step:     5\tLoss: 0.841\tAcc: 94.00%\n",
      "Step:     5\tLoss: 0.345\tAcc: 95.00%\n",
      "Step:     5\tLoss: 2.527\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.995\tAcc: 96.00%\n",
      "Step:     5\tLoss: 0.693\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.722\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.671\tAcc: 85.00%\n",
      "Step:     5\tLoss: 2.632\tAcc: 79.00%\n",
      "Step:     5\tLoss: 2.524\tAcc: 84.00%\n",
      "Step:     5\tLoss: 0.469\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.960\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.542\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.248\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.796\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.951\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.439\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.587\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.747\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.386\tAcc: 85.00%\n",
      "Step:     5\tLoss: 4.505\tAcc: 80.00%\n",
      "Step:     5\tLoss: 2.993\tAcc: 81.00%\n",
      "Step:     5\tLoss: 5.518\tAcc: 74.00%\n",
      "Step:     5\tLoss: 7.928\tAcc: 79.00%\n",
      "Step:     5\tLoss: 3.124\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.635\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.889\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.084\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.048\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.247\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.553\tAcc: 80.00%\n",
      "Step:     5\tLoss: 1.245\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.162\tAcc: 96.00%\n",
      "Step:     5\tLoss: 2.335\tAcc: 88.00%\n",
      "Step:     5\tLoss: 3.797\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.055\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.237\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.644\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.470\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.655\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.188\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.493\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.391\tAcc: 85.00%\n",
      "Step:     5\tLoss: 0.902\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.211\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.816\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.969\tAcc: 94.00%\n",
      "Step:     5\tLoss: 0.918\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.255\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.142\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.894\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.645\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.049\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.610\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.812\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.571\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.925\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.450\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.369\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.504\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.128\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.845\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.261\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.910\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.744\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.357\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.362\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.658\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.639\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.833\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.502\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.976\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.856\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.983\tAcc: 85.00%\n",
      "Step:     5\tLoss: 4.588\tAcc: 81.00%\n",
      "Step:     5\tLoss: 13.042\tAcc: 46.00%\n",
      "Step:     5\tLoss: 18.195\tAcc: 78.00%\n",
      "Step:     5\tLoss: 15.361\tAcc: 84.00%\n",
      "Step:     5\tLoss: 3.515\tAcc: 81.00%\n",
      "Step:     5\tLoss: 1.606\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.937\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.745\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.713\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.932\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.291\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.497\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.425\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.777\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.637\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.613\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.032\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.046\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.191\tAcc: 87.00%\n",
      "Step:     5\tLoss: 3.254\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.182\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.790\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.062\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.538\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.555\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.554\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.495\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.974\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.431\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.475\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.874\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.267\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.296\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.187\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.689\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.483\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.223\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.818\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.535\tAcc: 94.00%\n",
      "Step:     5\tLoss: 0.766\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.504\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.782\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.786\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.051\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.738\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.224\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.264\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.621\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.446\tAcc: 85.00%\n",
      "Step:     5\tLoss: 2.678\tAcc: 83.00%\n",
      "Step:     5\tLoss: 1.514\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.286\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.741\tAcc: 82.00%\n",
      "Step:     5\tLoss: 4.099\tAcc: 80.00%\n",
      "Step:     5\tLoss: 6.773\tAcc: 71.00%\n",
      "Step:     5\tLoss: 6.533\tAcc: 81.00%\n",
      "Step:     5\tLoss: 3.647\tAcc: 80.00%\n",
      "Step:     5\tLoss: 2.397\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.201\tAcc: 87.00%\n",
      "Step:     5\tLoss: 3.013\tAcc: 85.00%\n",
      "Step:     5\tLoss: 0.518\tAcc: 95.00%\n",
      "Step:     5\tLoss: 2.153\tAcc: 80.00%\n",
      "Step:     5\tLoss: 2.635\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.588\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.944\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.663\tAcc: 84.00%\n",
      "Step:     5\tLoss: 5.013\tAcc: 74.00%\n",
      "Step:     5\tLoss: 4.893\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.310\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.475\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.279\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.629\tAcc: 83.00%\n",
      "Step:     5\tLoss: 0.717\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.895\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.944\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.784\tAcc: 87.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     5\tLoss: 1.552\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.210\tAcc: 97.00%\n",
      "Step:     5\tLoss: 1.023\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.598\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.500\tAcc: 87.00%\n",
      "Step:     5\tLoss: 3.411\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.711\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.375\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.492\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.998\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.267\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.670\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.536\tAcc: 96.00%\n",
      "Step:     5\tLoss: 1.854\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.231\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.387\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.691\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.960\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.783\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.571\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.420\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.172\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.533\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.163\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.361\tAcc: 98.00%\n",
      "Step:     5\tLoss: 0.422\tAcc: 95.00%\n",
      "Step:     5\tLoss: 0.905\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.708\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.323\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.969\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.279\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.708\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.097\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.707\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.666\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.641\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.714\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.229\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.311\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.926\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.581\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.856\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.235\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.048\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.733\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.025\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.573\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.466\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.942\tAcc: 83.00%\n",
      "Step:     5\tLoss: 3.946\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.322\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.734\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.600\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.860\tAcc: 85.00%\n",
      "Step:     5\tLoss: 3.053\tAcc: 79.00%\n",
      "Step:     5\tLoss: 3.560\tAcc: 76.00%\n",
      "Step:     5\tLoss: 5.637\tAcc: 73.00%\n",
      "Step:     5\tLoss: 7.685\tAcc: 79.00%\n",
      "Step:     5\tLoss: 0.536\tAcc: 95.00%\n",
      "Step:     5\tLoss: 1.526\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.182\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.517\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.254\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.158\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.617\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.847\tAcc: 95.00%\n",
      "Step:     5\tLoss: 2.315\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.776\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.110\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.192\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.555\tAcc: 95.00%\n",
      "Step:     5\tLoss: 0.872\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.624\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.068\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.403\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.910\tAcc: 84.00%\n",
      "Step:     5\tLoss: 3.049\tAcc: 82.00%\n",
      "Step:     5\tLoss: 2.095\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.236\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.669\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.869\tAcc: 83.00%\n",
      "Step:     5\tLoss: 2.185\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.291\tAcc: 96.00%\n",
      "Step:     5\tLoss: 1.227\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.165\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.798\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.168\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.849\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.631\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.486\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.178\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.776\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.663\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.187\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.831\tAcc: 87.00%\n",
      "Step:     5\tLoss: 0.370\tAcc: 94.00%\n",
      "Step:     5\tLoss: 0.449\tAcc: 96.00%\n",
      "Step:     5\tLoss: 1.328\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.767\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.954\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.537\tAcc: 83.00%\n",
      "Step:     5\tLoss: 1.592\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.872\tAcc: 87.00%\n",
      "Step:     5\tLoss: 0.942\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.973\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.625\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.132\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.661\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.993\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.531\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.456\tAcc: 83.00%\n",
      "Step:     5\tLoss: 6.254\tAcc: 78.00%\n",
      "Step:     5\tLoss: 3.942\tAcc: 83.00%\n",
      "Step:     5\tLoss: 1.715\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.212\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.116\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.518\tAcc: 85.00%\n",
      "Step:     5\tLoss: 3.284\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.767\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.873\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.056\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.384\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.897\tAcc: 79.00%\n",
      "Step:     5\tLoss: 2.136\tAcc: 83.00%\n",
      "Step:     5\tLoss: 3.038\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.983\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.875\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.436\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.930\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.785\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.521\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.826\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.588\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.050\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.961\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.305\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.200\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.705\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.176\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.957\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.811\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.578\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.039\tAcc: 88.00%\n",
      "Step:     5\tLoss: 0.515\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.395\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.552\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.531\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.614\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.426\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.319\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.328\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.325\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.832\tAcc: 83.00%\n",
      "Step:     5\tLoss: 1.446\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.373\tAcc: 85.00%\n",
      "Step:     5\tLoss: 2.325\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.093\tAcc: 87.00%\n",
      "Step:     5\tLoss: 0.633\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.664\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.466\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.067\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.805\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.922\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.174\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.634\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.751\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.717\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.938\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.343\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.591\tAcc: 80.00%\n",
      "Step:     5\tLoss: 2.306\tAcc: 84.00%\n",
      "Step:     5\tLoss: 2.945\tAcc: 83.00%\n",
      "Step:     5\tLoss: 3.268\tAcc: 83.00%\n",
      "Step:     5\tLoss: 1.338\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.016\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.540\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.931\tAcc: 78.00%\n",
      "Step:     5\tLoss: 3.480\tAcc: 80.00%\n",
      "Step:     5\tLoss: 5.617\tAcc: 79.00%\n",
      "Step:     5\tLoss: 2.509\tAcc: 84.00%\n",
      "Step:     5\tLoss: 4.406\tAcc: 80.00%\n",
      "Step:     5\tLoss: 8.324\tAcc: 69.00%\n",
      "Step:     5\tLoss: 3.807\tAcc: 83.00%\n",
      "Step:     5\tLoss: 3.421\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.170\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.281\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.301\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.019\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.296\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.898\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.343\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.321\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.381\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.244\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.660\tAcc: 86.00%\n",
      "Step:     5\tLoss: 3.098\tAcc: 85.00%\n",
      "Step:     5\tLoss: 2.999\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.552\tAcc: 88.00%\n",
      "Step:     5\tLoss: 3.430\tAcc: 88.00%\n",
      "Step:     5\tLoss: 2.308\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.957\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.743\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.869\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.673\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.894\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.026\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.098\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.614\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.754\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.586\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.153\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.992\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.663\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.717\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.187\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.693\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.826\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.675\tAcc: 88.00%\n",
      "Step:     5\tLoss: 3.435\tAcc: 81.00%\n",
      "Step:     5\tLoss: 1.677\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.812\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.790\tAcc: 85.00%\n",
      "Step:     5\tLoss: 1.646\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.304\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.834\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.211\tAcc: 79.00%\n",
      "Step:     5\tLoss: 1.673\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.034\tAcc: 93.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     5\tLoss: 2.799\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.837\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.612\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.367\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.326\tAcc: 91.00%\n",
      "Step:     5\tLoss: 2.051\tAcc: 82.00%\n",
      "Step:     5\tLoss: 0.709\tAcc: 92.00%\n",
      "Step:     5\tLoss: 2.082\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.486\tAcc: 90.00%\n",
      "Step:     5\tLoss: 3.446\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.967\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.868\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.135\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.466\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.516\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.981\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.213\tAcc: 85.00%\n",
      "Step:     5\tLoss: 4.076\tAcc: 80.00%\n",
      "Step:     5\tLoss: 5.705\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.233\tAcc: 89.00%\n",
      "Step:     5\tLoss: 2.228\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.299\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.637\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.006\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.805\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.377\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.639\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.227\tAcc: 90.00%\n",
      "Step:     5\tLoss: 2.471\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.709\tAcc: 93.00%\n",
      "Step:     5\tLoss: 0.542\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.274\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.906\tAcc: 86.00%\n",
      "Step:     5\tLoss: 1.445\tAcc: 86.00%\n",
      "Step:     5\tLoss: 0.959\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.870\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.989\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.204\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.962\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.368\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.487\tAcc: 94.00%\n",
      "Step:     5\tLoss: 0.604\tAcc: 96.00%\n",
      "Step:     5\tLoss: 1.980\tAcc: 85.00%\n",
      "Step:     5\tLoss: 2.882\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.247\tAcc: 95.00%\n",
      "Step:     5\tLoss: 0.778\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.476\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.897\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.334\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.720\tAcc: 84.00%\n",
      "Step:     5\tLoss: 1.491\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.191\tAcc: 91.00%\n",
      "Step:     5\tLoss: 0.689\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.728\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.365\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.176\tAcc: 97.00%\n",
      "Step:     5\tLoss: 0.452\tAcc: 92.00%\n",
      "Step:     5\tLoss: 0.929\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.193\tAcc: 86.00%\n",
      "Step:     5\tLoss: 3.427\tAcc: 78.00%\n",
      "Step:     5\tLoss: 3.817\tAcc: 82.00%\n",
      "Step:     5\tLoss: 2.511\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.310\tAcc: 89.00%\n",
      "Step:     5\tLoss: 1.603\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.337\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.220\tAcc: 90.00%\n",
      "Step:     5\tLoss: 0.684\tAcc: 93.00%\n",
      "Step:     5\tLoss: 1.725\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.919\tAcc: 88.00%\n",
      "Step:     5\tLoss: 1.607\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.447\tAcc: 96.00%\n",
      "Step:     5\tLoss: 2.242\tAcc: 85.00%\n",
      "Step:     5\tLoss: 0.557\tAcc: 94.00%\n",
      "Step:     5\tLoss: 1.358\tAcc: 95.00%\n",
      "Step:     5\tLoss: 0.573\tAcc: 94.00%\n",
      "Step:     5\tLoss: 2.673\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.394\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.425\tAcc: 93.00%\n",
      "Step:     5\tLoss: 2.160\tAcc: 82.00%\n",
      "Step:     5\tLoss: 2.940\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.246\tAcc: 91.00%\n",
      "Step:     5\tLoss: 1.538\tAcc: 89.00%\n",
      "Step:     5\tLoss: 0.614\tAcc: 92.00%\n",
      "Step:     5\tLoss: 3.862\tAcc: 77.00%\n",
      "Step:     5\tLoss: 4.801\tAcc: 78.00%\n",
      "Step:     5\tLoss: 4.859\tAcc: 75.00%\n",
      "Step:     5\tLoss: 1.361\tAcc: 87.00%\n",
      "Step:     5\tLoss: 1.955\tAcc: 87.00%\n",
      "Step:     5\tLoss: 2.329\tAcc: 86.00%\n",
      "Step:     5\tLoss: 2.564\tAcc: 82.00%\n",
      "Step:     5\tLoss: 1.577\tAcc: 90.00%\n",
      "Step:     5\tLoss: 1.582\tAcc: 92.00%\n",
      "Step:     5\tLoss: 1.104\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.562\tAcc: 83.00%\n",
      "Step:     6\tLoss: 1.110\tAcc: 94.00%\n",
      "Step:     6\tLoss: 0.459\tAcc: 93.00%\n",
      "Step:     6\tLoss: 2.256\tAcc: 88.00%\n",
      "Step:     6\tLoss: 0.696\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.133\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.053\tAcc: 92.00%\n",
      "Step:     6\tLoss: 2.962\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.358\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.338\tAcc: 90.00%\n",
      "Step:     6\tLoss: 0.696\tAcc: 93.00%\n",
      "Step:     6\tLoss: 2.776\tAcc: 87.00%\n",
      "Step:     6\tLoss: 2.185\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.398\tAcc: 90.00%\n",
      "Step:     6\tLoss: 0.330\tAcc: 96.00%\n",
      "Step:     6\tLoss: 0.778\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.526\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.320\tAcc: 94.00%\n",
      "Step:     6\tLoss: 0.518\tAcc: 94.00%\n",
      "Step:     6\tLoss: 0.611\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.516\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.525\tAcc: 81.00%\n",
      "Step:     6\tLoss: 2.037\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.716\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.785\tAcc: 84.00%\n",
      "Step:     6\tLoss: 1.688\tAcc: 91.00%\n",
      "Step:     6\tLoss: 2.076\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.093\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.138\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.938\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.694\tAcc: 87.00%\n",
      "Step:     6\tLoss: 0.644\tAcc: 95.00%\n",
      "Step:     6\tLoss: 0.970\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.926\tAcc: 87.00%\n",
      "Step:     6\tLoss: 0.804\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.391\tAcc: 95.00%\n",
      "Step:     6\tLoss: 2.473\tAcc: 87.00%\n",
      "Step:     6\tLoss: 0.537\tAcc: 95.00%\n",
      "Step:     6\tLoss: 0.996\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.342\tAcc: 89.00%\n",
      "Step:     6\tLoss: 0.792\tAcc: 94.00%\n",
      "Step:     6\tLoss: 0.858\tAcc: 94.00%\n",
      "Step:     6\tLoss: 0.716\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.033\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.026\tAcc: 91.00%\n",
      "Step:     6\tLoss: 2.829\tAcc: 85.00%\n",
      "Step:     6\tLoss: 2.437\tAcc: 84.00%\n",
      "Step:     6\tLoss: 1.467\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.596\tAcc: 91.00%\n",
      "Step:     6\tLoss: 2.985\tAcc: 81.00%\n",
      "Step:     6\tLoss: 3.597\tAcc: 83.00%\n",
      "Step:     6\tLoss: 3.814\tAcc: 84.00%\n",
      "Step:     6\tLoss: 3.156\tAcc: 77.00%\n",
      "Step:     6\tLoss: 1.772\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.726\tAcc: 87.00%\n",
      "Step:     6\tLoss: 0.780\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.499\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.127\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.883\tAcc: 88.00%\n",
      "Step:     6\tLoss: 0.754\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.460\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.647\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.574\tAcc: 87.00%\n",
      "Step:     6\tLoss: 2.092\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.750\tAcc: 88.00%\n",
      "Step:     6\tLoss: 3.219\tAcc: 82.00%\n",
      "Step:     6\tLoss: 0.445\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.309\tAcc: 89.00%\n",
      "Step:     6\tLoss: 2.720\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.872\tAcc: 87.00%\n",
      "Step:     6\tLoss: 0.901\tAcc: 89.00%\n",
      "Step:     6\tLoss: 0.882\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.404\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.396\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.019\tAcc: 89.00%\n",
      "Step:     6\tLoss: 0.735\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.899\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.960\tAcc: 93.00%\n",
      "Step:     6\tLoss: 2.601\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.307\tAcc: 87.00%\n",
      "Step:     6\tLoss: 2.203\tAcc: 82.00%\n",
      "Step:     6\tLoss: 1.551\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.470\tAcc: 83.00%\n",
      "Step:     6\tLoss: 1.140\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.933\tAcc: 91.00%\n",
      "Step:     6\tLoss: 0.931\tAcc: 92.00%\n",
      "Step:     6\tLoss: 2.292\tAcc: 84.00%\n",
      "Step:     6\tLoss: 1.763\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.883\tAcc: 84.00%\n",
      "Step:     6\tLoss: 1.952\tAcc: 86.00%\n",
      "Step:     6\tLoss: 2.125\tAcc: 87.00%\n",
      "Step:     6\tLoss: 3.008\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.767\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.428\tAcc: 91.00%\n",
      "Step:     6\tLoss: 3.014\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.504\tAcc: 86.00%\n",
      "Step:     6\tLoss: 2.743\tAcc: 80.00%\n",
      "Step:     6\tLoss: 2.531\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.434\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.014\tAcc: 93.00%\n",
      "Step:     6\tLoss: 0.345\tAcc: 95.00%\n",
      "Step:     6\tLoss: 1.638\tAcc: 86.00%\n",
      "Step:     6\tLoss: 2.407\tAcc: 86.00%\n",
      "Step:     6\tLoss: 2.535\tAcc: 82.00%\n",
      "Step:     6\tLoss: 1.577\tAcc: 88.00%\n",
      "Step:     6\tLoss: 0.699\tAcc: 93.00%\n",
      "Step:     6\tLoss: 3.175\tAcc: 80.00%\n",
      "Step:     6\tLoss: 2.177\tAcc: 85.00%\n",
      "Step:     6\tLoss: 0.655\tAcc: 95.00%\n",
      "Step:     6\tLoss: 2.575\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.912\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.747\tAcc: 83.00%\n",
      "Step:     6\tLoss: 0.820\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.199\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.388\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.376\tAcc: 90.00%\n",
      "Step:     6\tLoss: 0.468\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.927\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.620\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.761\tAcc: 92.00%\n",
      "Step:     6\tLoss: 1.566\tAcc: 85.00%\n",
      "Step:     6\tLoss: 3.389\tAcc: 73.00%\n",
      "Step:     6\tLoss: 3.504\tAcc: 79.00%\n",
      "Step:     6\tLoss: 6.737\tAcc: 73.00%\n",
      "Step:     6\tLoss: 4.174\tAcc: 83.00%\n",
      "Step:     6\tLoss: 1.792\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.741\tAcc: 90.00%\n",
      "Step:     6\tLoss: 0.576\tAcc: 95.00%\n",
      "Step:     6\tLoss: 2.252\tAcc: 86.00%\n",
      "Step:     6\tLoss: 2.741\tAcc: 85.00%\n",
      "Step:     6\tLoss: 4.546\tAcc: 78.00%\n",
      "Step:     6\tLoss: 5.677\tAcc: 76.00%\n",
      "Step:     6\tLoss: 10.688\tAcc: 74.00%\n",
      "Step:     6\tLoss: 6.522\tAcc: 75.00%\n",
      "Step:     6\tLoss: 3.831\tAcc: 80.00%\n",
      "Step:     6\tLoss: 1.624\tAcc: 90.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     6\tLoss: 1.518\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.453\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.380\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.443\tAcc: 89.00%\n",
      "Step:     6\tLoss: 2.590\tAcc: 87.00%\n",
      "Step:     6\tLoss: 2.493\tAcc: 87.00%\n",
      "Step:     6\tLoss: 3.048\tAcc: 83.00%\n",
      "Step:     6\tLoss: 1.042\tAcc: 90.00%\n",
      "Step:     6\tLoss: 2.242\tAcc: 86.00%\n",
      "Step:     6\tLoss: 0.782\tAcc: 92.00%\n",
      "Step:     6\tLoss: 2.012\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.998\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.076\tAcc: 95.00%\n",
      "Step:     6\tLoss: 0.975\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.576\tAcc: 92.00%\n",
      "Step:     6\tLoss: 2.884\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.866\tAcc: 90.00%\n",
      "Step:     6\tLoss: 0.670\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.864\tAcc: 94.00%\n",
      "Step:     6\tLoss: 2.022\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.315\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.837\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.198\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.514\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.190\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.648\tAcc: 85.00%\n",
      "Step:     6\tLoss: 2.024\tAcc: 88.00%\n",
      "Step:     6\tLoss: 3.707\tAcc: 82.00%\n",
      "Step:     6\tLoss: 4.557\tAcc: 79.00%\n",
      "Step:     6\tLoss: 1.657\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.301\tAcc: 86.00%\n",
      "Step:     6\tLoss: 1.689\tAcc: 89.00%\n",
      "Step:     6\tLoss: 3.097\tAcc: 83.00%\n",
      "Step:     6\tLoss: 2.815\tAcc: 84.00%\n",
      "Step:     6\tLoss: 2.966\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.343\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.141\tAcc: 92.00%\n",
      "Step:     6\tLoss: 0.744\tAcc: 90.00%\n",
      "Step:     6\tLoss: 2.264\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.768\tAcc: 88.00%\n",
      "Step:     6\tLoss: 1.635\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.142\tAcc: 93.00%\n",
      "Step:     6\tLoss: 1.867\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.219\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.958\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.250\tAcc: 89.00%\n",
      "Step:     6\tLoss: 0.917\tAcc: 93.00%\n",
      "Step:     6\tLoss: 2.157\tAcc: 89.00%\n",
      "Step:     6\tLoss: 2.211\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.971\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.003\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.968\tAcc: 87.00%\n",
      "Step:     6\tLoss: 1.237\tAcc: 91.00%\n",
      "Step:     6\tLoss: 1.586\tAcc: 85.00%\n",
      "Step:     6\tLoss: 2.053\tAcc: 90.00%\n",
      "Step:     6\tLoss: 2.656\tAcc: 81.00%\n",
      "Step:     6\tLoss: 1.881\tAcc: 88.00%\n",
      "Step:     6\tLoss: 0.507\tAcc: 97.00%\n",
      "Step:     6\tLoss: 1.559\tAcc: 88.00%\n",
      "Step:     6\tLoss: 2.263\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.522\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.405\tAcc: 90.00%\n",
      "Step:     6\tLoss: 3.367\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.870\tAcc: 82.00%\n",
      "Step:     6\tLoss: 2.455\tAcc: 85.00%\n",
      "Step:     6\tLoss: 1.395\tAcc: 89.00%\n",
      "Step:     6\tLoss: 1.058\tAcc: 90.00%\n",
      "Step:     6\tLoss: 1.793\tAcc: 89.00%\n",
      "Step:     6\tLoss: 0.697\tAcc: 94.00%\n",
      "Step:     6\tLoss: 1.163\tAcc: 88.00%\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "training_epochs = 15 # 전체 dataset의 반복횟수\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(training_epochs) :\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch) :\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "                \n",
    "# 이거 겁나 오래걸림\n",
    "#         _, loss, acc = sess.run([train, tf.reduce_mean(cost), accuracy], feed_dict={X:batch_xs, y:batch_ys})\n",
    "#         print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
